{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/Chapter13_Using_Tensorflow_Lite_in_Android_Apps_Part_2ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 13: Using TensorFlow Lite in Android Apps - Part 2. 🧑‍💻📱"
      ],
      "metadata": {
        "id": "nsJ0t_ledpw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cover](https://www.systango.com/blog/wp-content/uploads/2020/03/Blog4.jpg)"
      ],
      "metadata": {
        "id": "1b1haZT-eC0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "❤️ **Hi mọi người** ❤️  \n",
        "\n",
        "Trong **phần 1** lần trước, tụi mình đã tìm hiểu sơ bộ cũng như lập trình thử một chương trình chạy **TensorFlow** trên hệ điều hành **Android** rồi ha. 📱🤖  \n",
        "\n",
        "Lần này, tụi mình sẽ đi **tiến xa hơn** với một ứng dụng **phức tạp hơn** tí nha. 🚀  \n",
        "\n",
        "🔹 **Về cơ bản, các bước quy trình làm vẫn tương tự như trước**.  \n",
        "🔹 **Điểm khác biệt chính** là việc tụi mình cần phải **điều chỉnh dữ liệu đầu vào** sao cho mô hình có thể hiểu được.  \n",
        "\n",
        "👉 **Trong phần tiếp theo này, tụi mình sẽ đối diện với việc sử dụng _dữ liệu dạng hình ảnh_**! 📸🎯  \n",
        "\n",
        "📌 Về mô hình, tụi mình sẽ lấy lại mô hình **phân loại chó mèo** ở [chương 12](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/Chapter12_An_Introduction_to_TensorFlow_Lite.ipynb) nha. 🐶🐱  \n",
        "\n",
        "✨ **Nào, không nói nhiều nữa!**  \n",
        "🔥 **Tụi mình bắt tay vào làm ngay thôi!** 💪😆"
      ],
      "metadata": {
        "id": "RuPKmLqWeHXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🚀 Xây dựng mô hình**  \n",
        "\n",
        "📌 Mọi người có thể **chạy lại code dưới đây** để **huấn luyện** và **tải mô hình về máy** nha. 🖥️📂  \n",
        "\n",
        "💡 Đồng thời, tụi mình cũng sẽ **phân tích yêu cầu đầu vào** của mô hình để đảm bảo dữ liệu được xử lý đúng cách trước khi đưa vào dự đoán. 🧐📊  \n",
        "\n",
        "👇 **Bắt đầu nào!** 🔥"
      ],
      "metadata": {
        "id": "5EXt7WSGfskT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Cài đặt các thư viện\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time as timer\n",
        "\n",
        "import tf_keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from datetime import timedelta"
      ],
      "metadata": {
        "id": "-qyueOnCgt91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
        "  return  image, label\n",
        "\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "num_examples = metadata.splits['train'].num_examples\n",
        "num_classes = metadata.features['label'].num_classes\n",
        "print(f\"Số lượng mẫu: {num_examples}\")\n",
        "print(f\"Số lượng nhãn: {num_classes}\")\n"
      ],
      "metadata": {
        "id": "vuvU9nfRdrGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cập nhật các tập train, validation, test\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_batches = raw_train.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = raw_test.map(format_image).batch(1)"
      ],
      "metadata": {
        "id": "-f9BkZq8gOtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tải MobileNetV2 với trọng số pre-trained trên ImageNet\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),  # Kích thước đầu vào của ảnh\n",
        "    include_top=False,         # Loại bỏ tầng phân loại đầu ra của MobileNetV2\n",
        "    weights='imagenet'         # Sử dụng trọng số pre-trained trên ImageNet\n",
        ")\n",
        "\n",
        "# Đóng băng các tầng của mô hình gốc (không huấn luyện lại)\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "YmtuuB-FgRBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_transfer_mobilenet = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model_transfer_mobilenet.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qvpnfMORgTW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timer.time()\n",
        "history = model_transfer_mobilenet.fit(train_batches, epochs=5, validation_data=validation_batches)\n",
        "end_time = timer.time()"
      ],
      "metadata": {
        "id": "qp_Dtz9OgVuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lưu mô hình lại\n",
        "model_transfer_mobilenet_path = 'model_transfer_mobilenet.h5'\n",
        "model_transfer_mobilenet.save(model_transfer_mobilenet_path)"
      ],
      "metadata": {
        "id": "ORNVct_1gZ2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Thời gian huấn luyện mô hình: {str(timedelta(seconds=end_time - start_time))}\")"
      ],
      "metadata": {
        "id": "lKesqSUWgYSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load lại mô hình từ file.h5\n",
        "model_transfer_mobilenet = tf.keras.models.load_model(model_transfer_mobilenet_path)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_transfer_mobilenet)\n",
        "tflite_model_transfer = converter.convert()"
      ],
      "metadata": {
        "id": "0z3Bs7c9gbiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lưu mô hình TFLite\n",
        "tflite_model_transfer_path = 'model_transfer_mobilenet.tflite'\n",
        "with open(tflite_model_transfer_path, \"wb\") as f:\n",
        "    f.write(tflite_model_transfer)"
      ],
      "metadata": {
        "id": "mtE_RSimgdz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mọi người nhớ download mô hình tflite về để làm tiếp các bước sau nha."
      ],
      "metadata": {
        "id": "TAM87jjniZ_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_13_2/10.png?raw=true)"
      ],
      "metadata": {
        "id": "7QmACLvTimrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📊 Phân tích đầu vào của mô hình**  \n",
        "\n",
        "Ở đây tụi mình có thể quan sát thấy dòng chuẩn hóa này:  \n",
        "\n",
        "```python\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),  # Kích thước đầu vào của ảnh\n",
        "    include_top=False,         # Loại bỏ tầng phân loại đầu ra của MobileNetV2\n",
        "    weights='imagenet'         # Sử dụng trọng số pre-trained trên ImageNet\n",
        ")\n",
        "```  \n",
        "\n",
        "📌 Vậy có nghĩa là kích thước ảnh đầu vào của mô hình chúng ta là **224 x 224** với **3 kênh màu**. Khi triển khai thành ứng dụng **Android**, chúng ta cũng sẽ cần phải **tuân thủ theo chuẩn đầu vào này**. 📷  \n",
        "\n",
        "💡 Tuy nhiên, ảnh chụp từ điện thoại không phải lúc nào cũng có kích thước như vậy. Chúng có thể có kích thước bất kỳ, chẳng hạn như **395 x 500** dưới đây. 🖼️"
      ],
      "metadata": {
        "id": "P9BtxUGbgM19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_13_2/1.png?raw=true)"
      ],
      "metadata": {
        "id": "_q0T3CCBJFbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do đó tụi mình sẽ cần một hàm để có thể tinh chỉnh kích thước lại về 224 x 224 nha. Và điều này có thể được thực hiện thông qua thư viện **Bitmap** trong**Android** nha.\n",
        "\n",
        "```kotlin\n",
        "val scaledBitmap = Bitmap.createScaledBitmap(bitmap, 224, 224, false)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "I_aRkduEhzyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌 **Tiếp đến là kích thước Tensor nha.** 🧩  \n",
        "\n",
        "Như mô hình đã định nghĩa trước đó, chúng ta cần đảm bảo rằng **Tensor** phải đúng định dạng **224 x 224 x 3**. Ngoài ra, trong quá trình chuẩn bị mô hình, các giá trị đầu vào đều được **chuẩn hóa** trong khoảng **0 đến 1**. Vì vậy, trong ứng dụng **Android**, chúng ta cũng phải thực hiện điều tương tự. 🎯  \n",
        "\n",
        "📝 Để làm điều này, chúng ta có thể sử dụng đoạn code sau:  \n",
        "\n",
        "```kotlin\n",
        "val byteBuffer = ByteBuffer.allocateDirect(4 * 224 * 224 * 3)\n",
        "byteBuffer.order(ByteOrder.nativeOrder())\n",
        "```  \n",
        "\n",
        "📌 Ở đây, bởi vì chúng ta đưa các giá trị về dạng **float** (0 đến 1), mà kiểu **float** có kích thước **4 byte**, nên tổng kích thước **ByteArray** sẽ là `4 x 224 x 224 x 3` nha. 📊"
      ],
      "metadata": {
        "id": "olw7XU-HgLhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bởi vì trong Android, mỗi pixel của hình ảnh được lưu dưới dạng **số nguyên 32-bit**, theo định dạng **ARGB** (Alpha, Red, Green, Blue). Ví dụ, một pixel có thể có giá trị **0x0010FF10**:  \n",
        "\n",
        "- **00**: Giá trị **Alpha** (độ trong suốt), có thể bỏ qua.  \n",
        "- **10**: Giá trị **Red (R) = 0x10**.  \n",
        "- **FF**: Giá trị **Green (G) = 0xFF**.  \n",
        "- **10**: Giá trị **Blue (B) = 0x10**.  \n",
        "\n",
        "Để chuẩn hóa các giá trị màu này về khoảng **0 đến 1**, bạn chỉ cần **chia mỗi kênh màu cho 255**:  \n",
        "\n",
        "- **Red**: 0x10 / 255 = 16 / 255 ≈ 0.06275.  \n",
        "- **Green**: 0xFF / 255 = 225 / 255 = 1.0.\n",
        "- **Blue**: 0x10 / 255 = 16 / 255 ≈ 0.06275.\n",
        "\n"
      ],
      "metadata": {
        "id": "iseXL2VWsIYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌 **Sau khi hiểu nguyên lý rồi, giờ chúng ta bắt tay vào code nha.** 💻✨  \n",
        "\n",
        "🔹 Đầu tiên, chúng ta cần chuyển đổi ảnh **Bitmap** thành một mảng số nguyên có kích thước **224 × 224**, rồi trích xuất các giá trị pixel bằng API `getPixels()`:  \n",
        "\n",
        "```kotlin\n",
        "val intValues = IntArray(224 * 224)\n",
        "scaledBitmap.getPixels(intValues, 0, 224, 0, 0, 224, 224)\n",
        "```  \n",
        "\n",
        "🔹 Tiếp theo, chúng ta **lặp qua mảng này**, đọc từng pixel và **chuẩn hóa** chúng thành giá trị `float` từ **0 đến 1**.  \n",
        "\n",
        "📝 **Dịch bit (bit shifting) để trích xuất từng kênh màu từ giá trị ARGB 32-bit**:  \n",
        "- **Red (R)**: `val red = (pixel shr 16) and 0xFF`  \n",
        "- **Green (G)**: `val green = (pixel shr 8) and 0xFF`  \n",
        "- **Blue (B)**: `val blue = pixel and 0xFF`  \n",
        "\n",
        "Sau khi trích xuất, chúng ta chuẩn hóa giá trị về khoảng **[0, 1]** bằng cách chia cho `255.0f`.  \n",
        "\n",
        "📝 **Code hoàn chỉnh để chuyển đổi ảnh thành Tensor**:  \n",
        "\n",
        "```kotlin\n",
        "var pixel = 0\n",
        "for (i in 0 until 224) {\n",
        "    for (j in 0 until 224) {\n",
        "        val input = intValues[pixel++]\n",
        "        byteBuffer.putFloat(((input.shr(16) and 0xFF) / 255.0f))\n",
        "        byteBuffer.putFloat(((input.shr(8) and 0xFF) / 255.0f))\n",
        "        byteBuffer.putFloat(((input and 0xFF) / 255.0f))\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "📌 **Vậy là chúng ta đã sẵn sàng đưa ảnh vào mô hình để chạy dự đoán rồi đó.** 🚀"
      ],
      "metadata": {
        "id": "GbjwAX1Dt3tV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oa, vậy là tụi mình gần đến đích rồi á. 🚀  \n",
        "\n",
        "Bây giờ tụi mình chỉ cần xử lý kết quả từ mô hình TensorFlow Lite nữa thôi. Đầu tiên, tụi mình cần một mảng để có thể lưu trữ đầu ra của mô hình.  \n",
        "\n",
        "Tụi mình **không nhất thiết phải dùng `ByteArray`** đâu nha, vì đầu ra là `float` nên tụi mình có thể sử dụng `FloatArray` chẳng hạn.  \n",
        "\n",
        "Ví dụ, trong bài toán **Dogs vs. Cats** 🐶🐱, mô hình có **hai nhãn (dog, cat)** và **lớp output có 2 neuron**. Vì vậy, bạn cần một mảng chứa **2 giá trị float**, mỗi giá trị tương ứng với xác suất của từng lớp:  \n",
        "\n",
        "```kotlin\n",
        "val result = Array(1) { FloatArray(2) }\n",
        "```\n",
        "\n",
        "#### Giải thích cấu trúc mảng:  \n",
        "- `Array(1)`: Tạo một mảng ngoài có **1 phần tử**, tượng trưng cho batch size = 1.  \n",
        "- `FloatArray(2)`: Mỗi phần tử là một mảng chứa **2 giá trị float**, tương ứng với đầu ra `[cat_prob, dog_prob]`.  \n",
        "\n",
        "Tương tự trong Python 🐍, đầu ra có thể có dạng:  \n",
        "\n",
        "```python\n",
        "[[1.0, 0.0]]  # Xác suất 100% là mèo, 0% là chó\n",
        "```\n",
        "\n",
        "Tụi mình định nghĩa trong **Kotlin** như vậy, giống tương tự với đầu ra của mô hình trong **Python** á.  \n",
        "\n",
        "Cuối cùng, để chạy mô hình thì tụi mình chỉ cần dùng lệnh như lúc trước nha.  \n",
        "\n",
        "```kotlin\n",
        "interpreter.run(byteBuffer, result)\n",
        "```  "
      ],
      "metadata": {
        "id": "BDXHXHARvhWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uầy, coi như là hoàn thành rồi á. 🎉  \n",
        "\n",
        "Đúc kết lại thì theo mình cảm nhận nha.  \n",
        "\n",
        "Thực chất việc chuyển đổi sang sử dụng mô hình trong app **Android** cũng không khó lắm. Thứ duy nhất mà mọi người có thể cảm thấy hơi khó là việc xử lý dữ liệu khi mà chuyển đổi qua thì có tí bất cập.  \n",
        "\n",
        "- Trong **Python** 🐍 thì việc xử lý dữ liệu có vẻ trông nhẹ nhàng hơn nhiều với các thư viện hỗ trợ nhanh như **Numpy** chẳng hạn.  \n",
        "- Tuy nhiên, khi chuyển sang với **Kotlin** 📱 có khá nhiều thứ cầu kỳ hơn như là chúng ta cần phải xác định được chính xác kiểu dữ liệu hay cách chuyển đổi: **FloatArray, ByteBuffer, IntArray hay ByteBuffer,...**  \n",
        "\n",
        "Ấy, chỉ có như vậy thôi á.  \n",
        "\n",
        "Lý thuyết đủ nhiều rồi, bây giờ chúng ta đi vào xây dựng nhanh ứng dụng trên **Android Studio** nha. 💻🚀"
      ],
      "metadata": {
        "id": "4N9Y73QrwqTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xây dựng hoàn chỉnh ứng dụng."
      ],
      "metadata": {
        "id": "L4ECchKfxxJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thêm thư viện cho hệ thống bên trong file **build.gradle.kts** của thư mục **app**.\n",
        "\n",
        "\n",
        "```kotlin\n",
        "implementation(\"org.tensorflow:tensorflow-lite:2.15.0\")\n",
        "```\n"
      ],
      "metadata": {
        "id": "ntNyrOq3xzyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_13_2/2.png?raw=true)"
      ],
      "metadata": {
        "id": "8VO2bh7vJNwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "À nhớ là chỉnh luôn phần này trong **gradle** cho tương thích với thiết lập của mọi người, tránh bị tình trạng lỗi như lần trước nha. Ở mình thì sẽ là như này."
      ],
      "metadata": {
        "id": "7WV5dFct7UMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_13_2/3.png?raw=true)"
      ],
      "metadata": {
        "id": "sUtYnWKPJScf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sau khi xong thì nhấn **biểu tượng con voi** trên thanh công cụ trên cùng để sync với hệ thống nha."
      ],
      "metadata": {
        "id": "wFYU1gx27vVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiếp đến là tạo thư mục **assets** bên trong **main** và thêm mô hình vào như ở phần 1."
      ],
      "metadata": {
        "id": "cg0ktSIy09hF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_13_2/4.png?raw=true)"
      ],
      "metadata": {
        "id": "Osv6wGWYJUk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uki, bây giờ là đến phần giao diện bây trong file **activity_main.xml**. Mọi người có thể copy đoạn code dưới đây nha.\n",
        "\n",
        "```xml\n",
        "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
        "<LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n",
        "    android:layout_width=\"match_parent\"\n",
        "    android:layout_height=\"match_parent\"\n",
        "    android:orientation=\"vertical\"\n",
        "    android:padding=\"16dp\">\n",
        "\n",
        "    <Button\n",
        "        android:id=\"@+id/selectButton\"\n",
        "        android:layout_width=\"wrap_content\"\n",
        "        android:layout_height=\"wrap_content\"\n",
        "        android:text=\"Chọn ảnh\" />\n",
        "\n",
        "    <ImageView\n",
        "        android:id=\"@+id/imageView\"\n",
        "        android:layout_width=\"match_parent\"\n",
        "        android:layout_height=\"0dp\"\n",
        "        android:layout_weight=\"1\"\n",
        "        android:scaleType=\"centerInside\"\n",
        "        android:contentDescription=\"Ảnh được chọn\" />\n",
        "\n",
        "    <TextView\n",
        "        android:id=\"@+id/resultView\"\n",
        "        android:layout_width=\"match_parent\"\n",
        "        android:layout_height=\"wrap_content\"\n",
        "        android:textSize=\"18sp\"\n",
        "        android:textAlignment=\"center\"\n",
        "        android:layout_marginTop=\"16dp\" />\n",
        "</LinearLayout>\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "kCbyXhqA1ScN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_13_2/5.png?raw=true)"
      ],
      "metadata": {
        "id": "g8O4Tnz3JXyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiếp đến là tạo thư viện **TFLiteModelHelper** giống như phần 1 nha.\n",
        "\n",
        "```kotlin\n",
        "package com.example.chapter_13_part_2\n",
        "\n",
        "import android.content.res.AssetManager\n",
        "import java.io.FileInputStream\n",
        "import java.nio.ByteBuffer\n",
        "import java.nio.channels.FileChannel\n",
        "\n",
        "object TFLiteModelHelper {\n",
        "    fun loadModelFile(assetManager: AssetManager, modelPath: String): ByteBuffer {\n",
        "        val fileDescriptor = assetManager.openFd(modelPath)\n",
        "        val inputStream = FileInputStream(fileDescriptor.fileDescriptor)\n",
        "        val fileChannel = inputStream.channel\n",
        "        val startOffset = fileDescriptor.startOffset\n",
        "        val declaredLength = fileDescriptor.declaredLength\n",
        "        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "Mọi người nhớ điều chỉnh đoạn này cho giống với tên project của mọi người nha.\n",
        "\n",
        "\n",
        "```kotlin\n",
        "package com.example.chapter_13_part_2\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ejPJXSW92j3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uki, hòm hòm rồi.\n",
        "\n",
        "Cuối cùng là tinh chỉnh lại code trong file **MainActivity** nữa rồi thiết lập device và chạy nha.\n",
        "\n",
        "```kotlin\n",
        "package com.example.chapter_13_part_2\n",
        "\n",
        "import android.app.Activity\n",
        "import android.content.Intent\n",
        "import android.graphics.Bitmap\n",
        "import android.net.Uri\n",
        "import android.os.Bundle\n",
        "import android.provider.MediaStore\n",
        "import android.widget.Button\n",
        "import android.widget.ImageView\n",
        "import android.widget.TextView\n",
        "import android.widget.Toast\n",
        "import androidx.appcompat.app.AppCompatActivity\n",
        "import org.tensorflow.lite.Interpreter\n",
        "import java.io.IOException\n",
        "import java.nio.ByteBuffer\n",
        "import java.nio.ByteOrder\n",
        "\n",
        "class MainActivity : AppCompatActivity() {\n",
        "    private lateinit var interpreter: Interpreter\n",
        "    private lateinit var selectButton: Button\n",
        "    private lateinit var imageView: ImageView\n",
        "    private lateinit var resultView: TextView\n",
        "    private val REQUEST_IMAGE = 1\n",
        "\n",
        "    override fun onCreate(savedInstanceState: Bundle?) {\n",
        "        super.onCreate(savedInstanceState)\n",
        "        setContentView(R.layout.activity_main)\n",
        "\n",
        "        selectButton = findViewById(R.id.selectButton)\n",
        "        imageView = findViewById(R.id.imageView)\n",
        "        resultView = findViewById(R.id.resultView)\n",
        "\n",
        "        try {\n",
        "            val modelBuffer = TFLiteModelHelper.loadModelFile(assets, \"model_transfer_mobilenet.tflite\")\n",
        "            interpreter = Interpreter(modelBuffer)\n",
        "        } catch (e: IOException) {\n",
        "            Toast.makeText(this, \"Lỗi khi tải mô hình\", Toast.LENGTH_LONG).show()\n",
        "            finish()\n",
        "        }\n",
        "\n",
        "        selectButton.setOnClickListener {\n",
        "            val intent = Intent(Intent.ACTION_PICK, MediaStore.Images.Media.EXTERNAL_CONTENT_URI)\n",
        "            startActivityForResult(intent, REQUEST_IMAGE)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    override fun onActivityResult(requestCode: Int, resultCode: Int, data: Intent?) {\n",
        "        super.onActivityResult(requestCode, resultCode, data)\n",
        "        if (requestCode == REQUEST_IMAGE && resultCode == Activity.RESULT_OK && data != null) {\n",
        "            try {\n",
        "                val selectedImage: Uri? = data.data\n",
        "                val bitmap = MediaStore.Images.Media.getBitmap(contentResolver, selectedImage)\n",
        "                imageView.setImageBitmap(bitmap)\n",
        "\n",
        "                // Xử lý ảnh và chạy suy luận\n",
        "                val inputBuffer = preprocessImage(bitmap)\n",
        "                val output = runInference(inputBuffer)\n",
        "                displayResult(output)\n",
        "            } catch (e: IOException) {\n",
        "                Toast.makeText(this, \"Lỗi khi tải ảnh\", Toast.LENGTH_LONG).show()\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    private fun preprocessImage(bitmap: Bitmap): ByteBuffer {\n",
        "        val inputWidth = 224 // Kích thước đầu vào của mô hình\n",
        "        val inputHeight = 224\n",
        "        val scaledBitmap = Bitmap.createScaledBitmap(bitmap, inputWidth, inputHeight, false)\n",
        "        val intValues = IntArray(inputWidth * inputHeight)\n",
        "        scaledBitmap.getPixels(intValues, 0, inputWidth, 0, 0, inputWidth, inputHeight)\n",
        "\n",
        "        val byteBuffer = ByteBuffer.allocateDirect(4 * inputWidth * inputHeight * 3)\n",
        "        byteBuffer.order(ByteOrder.nativeOrder())\n",
        "\n",
        "        for (i in 0 until inputWidth) {\n",
        "            for (j in 0 until inputHeight) {\n",
        "                val pixel = intValues[i * inputWidth + j]\n",
        "                byteBuffer.putFloat(((pixel shr 16) and 0xFF) / 255.0f) // R\n",
        "                byteBuffer.putFloat(((pixel shr 8) and 0xFF) / 255.0f)  // G\n",
        "                byteBuffer.putFloat((pixel and 0xFF) / 255.0f)         // B\n",
        "            }\n",
        "        }\n",
        "        return byteBuffer\n",
        "    }\n",
        "\n",
        "    private fun runInference(inputBuffer: ByteBuffer): FloatArray {\n",
        "        val output = Array(1) { FloatArray(2) } // Giả sử mô hình có 2 lớp đầu ra\n",
        "        interpreter.run(inputBuffer, output)\n",
        "        return output[0]\n",
        "    }\n",
        "\n",
        "    private fun displayResult(output: FloatArray) {\n",
        "        val labels = arrayOf(\"Mèo\", \"Chó\") // Điều chỉnh theo nhãn của mô hình\n",
        "        val maxIndex = output.indices.maxByOrNull { output[it] } ?: -1\n",
        "        val resultText = if (maxIndex != -1) {\n",
        "            \"Dự đoán: ${labels[maxIndex]} với độ tin cậy %.2f%%\".format(output[maxIndex] * 100)\n",
        "        } else {\n",
        "            \"Không thể dự đoán\"\n",
        "        }\n",
        "        resultView.text = resultText\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9ZV2WPk82wLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mọi người nhớ điều chỉnh đoạn này cho giống với tên project của mọi người nha.\n",
        "\n",
        "\n",
        "```kotlin\n",
        "package com.example.chapter_13_part_2\n",
        "```"
      ],
      "metadata": {
        "id": "8enmFNH6-pql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_13_2/6.png?raw=true)"
      ],
      "metadata": {
        "id": "9bnQOqJ4JbAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xong thì ấn lại một lần cho chắc rồi mới thiết lập thiết bị nha (bạn nào thiết lập ở phần 1 rồi thì hệ thống tự lưu nên không cần tạo lại, chỉ cần chọn thôi).\n",
        "\n",
        "Thiết lập xong thì nhấn **Run (nút mũi tên play ở trên)** là xong nha."
      ],
      "metadata": {
        "id": "htP0iEEI30gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_13_2/7.png?raw=true)"
      ],
      "metadata": {
        "id": "HgxA6DoJJexd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ở đây mình thử tải ảnh một con chó về và test thử nha."
      ],
      "metadata": {
        "id": "L38M8noe-_6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_13_2/8.png?raw=true)"
      ],
      "metadata": {
        "id": "OXxFYp82Jg68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kết quả đây nha."
      ],
      "metadata": {
        "id": "uYYWC15k_vMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_13_2/9.png?raw=true)"
      ],
      "metadata": {
        "id": "ibEenhtyJjYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Góc mở mang. 🐟"
      ],
      "metadata": {
        "id": "CHxTQENfAp-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![meme](https://th.bing.com/th/id/OIP.Vz_8_bhcQgpz53z5JxuxOAHaFm?w=237&h=180&c=7&r=0&o=5&dpr=1.4&pid=1.7)"
      ],
      "metadata": {
        "id": "SC6GkW3rBNSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tạo mã tự động từ mô hình TensorFlow Lite**  \n",
        "\n",
        "Hiện tại, TensorFlow Lite cung cấp một **công cụ thử nghiệm** giúp **tạo mã tự động** từ metadata của mô hình. Điều này giúp bạn tránh phải xử lý trực tiếp với **ByteBuffer cấp thấp** như đã làm trong các phần trước.  \n",
        "\n",
        "#### **Cách sử dụng:**  \n",
        "1. **Thêm metadata vào mô hình TensorFlow Lite** khi thực hiện chuyển đổi (`.tflite`).  \n",
        "2. **Sử dụng công cụ tạo mã** để tự động sinh ra các đoạn code tương tác với mô hình.  \n",
        "\n",
        "#### **Tham khảo thêm:**  \n",
        "- **Tài liệu chính thức của TensorFlow Lite** để xem cách tạo metadata cho mô hình.  \n",
        "- **Thư viện TensorFlow Lite Model Maker**, giúp đơn giản hóa quá trình huấn luyện và triển khai mô hình trên Android.  \n",
        "\n",
        "💡 **Lợi ích:**  \n",
        "✅ Giảm bớt xử lý thủ công với `ByteBuffer`.  \n",
        "✅ Dễ dàng sử dụng mô hình mà không cần thao tác dữ liệu phức tạp.  \n",
        "✅ Tăng tốc độ phát triển ứng dụng AI trên Android. 🚀"
      ],
      "metadata": {
        "id": "gNGqC5TZBXG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tài liệu tham khảo: 📚🔗  \n",
        "\n",
        "Ngoài ra, mọi người cũng có thể tham khảo thêm nhiều ứng dụng khác sử dụng **TensorFlow Lite** [ở đây](https://github.com/margaretmz/awesome-tensorflow-lite?tab=readme-ov-file) nha.  \n",
        "\n",
        "Chúng bao gồm nhiều dự án khác nhau như là: phân loại ảnh 🖼️, hỏi và trả lời ❓💡, nhận diện bàn tay ✋,..."
      ],
      "metadata": {
        "id": "b-Vrd407B6v9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tổng kết hết chương 3: 🎯  \n",
        "\n",
        "Tụi mình đã học thêm được nhiều thứ hay ho từ việc ứng dụng mô hình **TensorFlow** vào bên trong ứng dụng **Android**, qua đó mở rộng thêm khả năng triển khai dự án.  \n",
        "\n",
        "- Cách xử lý file **build.gradle.kts** ⚙️.  \n",
        "- Thiết kế giao diện trong file **activity_main.xml** 🎨.  \n",
        "- Thiết kế luồng xử lý chính trong file **MainActivity.kt** 🏗️."
      ],
      "metadata": {
        "id": "sDeZ9HUVCYfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cảm ơn mọi người đã quan tâm và theo dõi nha! 💖 Nếu thấy hay, có thể cho mình xin **1 sao** ⭐ trên repository nha.  \n",
        "\n",
        "### Thông tin liên lạc 📩  \n",
        "- **Email**: trinhhuynhthinhkhang.work@gmail.com  \n",
        "- **Page Facebook**: Nhật ký học tập của Khang  \n",
        "\n",
        "Mọi người có thể ủng hộ mình **ly cà phê** ☕ thông qua QR sau nha. Mình sẽ vui cả ngày luôn ý! 😆  \n",
        "\n",
        "<img src=\"https://github.com/Tkag0001/Tkag0001/blob/main/imgs/uzc4uwus.png?raw=true\" width=\"150px\">"
      ],
      "metadata": {
        "id": "vlJHnrKbEK3R"
      }
    }
  ]
}