{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 10305862,
          "datasetId": 6378565,
          "databundleVersionId": 10609746
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 10318651,
          "datasetId": 6382919,
          "databundleVersionId": 10624181
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 4222990,
          "datasetId": 2489101,
          "databundleVersionId": 4280135
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 276428,
          "datasetId": 115588,
          "databundleVersionId": 288752
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/Chapter_8_Using_Tensorflow_to_Create_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 8: Using Tensorflow to Create Text  \n",
        "### Hi, ch√†o m·ªçi ng∆∞·ªùi, t·ª•i m√¨nh l·∫°i g·∫∑p nhau r·ªìi üåª.  \n",
        "### Trong ch∆∞∆°ng n√†y t·ª•i m√¨nh s·∫Ω t√¨m hi·ªÉu v·ªÅ c√°ch s·ª≠ d·ª•ng c√°c m√¥ h√¨nh ƒë·ªÉ t·∫°o ra vƒÉn b·∫£n. N√≥i n√¥m na l√† gi·ªëng nh∆∞ c√°ch m√† c√°c chatbot hi·ªán t·∫°i t·∫°o ra c√¢u tr·∫£ l·ªùi cho m·ªçi ng∆∞·ªùi √°. Nh∆∞ng c√°i n√†y ·ªü c·∫•p ƒë·ªô s∆° khai h∆°n. üòä  "
      ],
      "metadata": {
        "id": "yooo41ZlEgpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![predictext](https://cgupta.tech/images/rnn_representative.png)"
      ],
      "metadata": {
        "id": "jrzNuwTVGAiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nh∆∞ m·ªçi ng∆∞·ªùi th·∫•y ·ªü b·ª©c h√¨nh tr√™n, ƒë√¢y l√† c∆° ch·∫ø ch√≠nh c·ªßa t√≠nh nƒÉng t·∫°o vƒÉn b·∫£n trong ch∆∞∆°ng n√†y.  \n",
        "\n",
        "Tr∆∞·ªõc khi ƒëi v√†o ph√¢n t√≠ch n√≥ th√¨ ch√∫ng ta c√πng √¥n l·∫°i c√°c ch∆∞∆°ng tr∆∞·ªõc t√≠ nh√°. üòä  \n",
        "\n",
        "---\n",
        "\n",
        "- ·ªû **ch∆∞∆°ng 5**, m·ªçi ng∆∞·ªùi t√¨m hi·ªÉu v·ªÅ c∆° ch·∫ø **Tokenize** ƒë·ªÉ t√°ch vƒÉn b·∫£n, t·∫°o t·ª´ ƒëi·ªÉn, m√£ h√≥a ·ªü c·∫•p t·ª´ hay k√Ω t·ª± r·ªìi th√™m b·ªô ƒë·ªám hay padding v√†o.  \n",
        "\n",
        "- Sang ƒë·∫øn **ch∆∞∆°ng 6**, ch√∫ng ta t√¨m hi·ªÉu v·ªÅ c∆° ch·∫ø **Embedding - Vector bi·ªÉu di·ªÖn** tr√™n c√°c chi·ªÅu kh√¥ng gian cao h∆°n.  \n",
        "\n",
        "- V√† g·∫ßn ƒë√¢y nh·∫•t l√† **ch∆∞∆°ng 7**, t√¨m hi·ªÉu v·ªÅ m·∫°ng h·ªìi quy **RNN** v√† l·ªõp **LSTM** qua ƒë√≥ c·∫£i thi·ªán kh·∫£ nƒÉng hi·ªÉu ng·ªØ nghƒ©a theo tr√¨nh t·ª± c·ªßa chu·ªói.  \n",
        "\n",
        "B√¢y gi·ªù ƒë·∫øn v·ªõi **ch∆∞∆°ng 8**, t·ª•i m√¨nh s·∫Ω t√¨m hi·ªÉu v·ªÅ c∆° ch·∫ø **t·∫°o/sinh vƒÉn b·∫£n** c·ªßa c√°c m√¥ h√¨nh. Th·∫≠t ra n√≥ kh√¥ng kh√≥ nh∆∞ m·ªçi ng∆∞·ªùi nghƒ© m√† r·∫•t l√† ƒë∆°n gi·∫£n. Ch√∫ng ƒë·ªÅu d·ª±a tr√™n nh·ªØng c∆° ch·∫ø tr∆∞·ªõc gi·ªù ch√∫ng ta h·ªçc, tuy nhi√™n kh√°c ·ªü kh√¢u x·ª≠ l√Ω v√† bi·∫øn ƒë·ªïi d·ªØ li·ªáu t√≠.  \n",
        "\n",
        "V·∫≠y s·ª± kh√°c nhau n√†y l√† g√¨, t·ª•i m√¨nh s·∫Ω c√πng t√¨m hi·ªÉu nh√°. üåü  "
      ],
      "metadata": {
        "id": "0OpPX-_LILXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![process_text](https://i.imgur.com/7kOLuRM.png)"
      ],
      "metadata": {
        "id": "OYXNgZabNqiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![padding_text](https://i.imgur.com/QOcbcqC.png)"
      ],
      "metadata": {
        "id": "BGLvJdjeOSzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong c√°c b√†i to√°n tr∆∞·ªõc ƒë√¢y c·ªßa ch√∫ng ta, t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh **x·ª≠ l√Ω d·ªØ li·ªáu vƒÉn b·∫£n sang d·∫°ng s·ªë** v√† **ph√¢n lo·∫°i ch√∫ng** d·ª±a tr√™n **nh√£n c√≥ s·∫µn** c·ªßa d·ªØ li·ªáu hu·∫•n luy·ªán tr∆∞·ªõc ƒë√≥. üìä  \n",
        "\n",
        "Th∆∞·ªùng th√¨ **s·ªë l∆∞·ª£ng nh√£n kh√° √≠t**, v√≠ d·ª• nh∆∞ ch·ªâ c√≥ hai nh√£n **\"t√≠ch c·ª±c\"** v√† **\"ti√™u c·ª±c\"** trong b√†i to√°n ph√¢n t√≠ch c·∫£m x√∫c, ho·∫∑c v√†i nh√£n c·ª• th·ªÉ trong b√†i to√°n ph√¢n lo·∫°i vƒÉn b·∫£n. üè∑Ô∏è"
      ],
      "metadata": {
        "id": "qVQotDeuLNQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![classify_sentiment](https://media.mlhive.com/i/max/YbAcdK8b2Q4T5Ed4fIf.png)"
      ],
      "metadata": {
        "id": "jUEX7M8yOlLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gi·ªù ƒë√¢y ƒë·∫øn v·ªõi **b√†i to√°n t·∫°o/sinh vƒÉn b·∫£n**, thay v√¨ **ph√¢n lo·∫°i v·ªõi c√°c nh√£n c·ªë ƒë·ªãnh**, ch√∫ng ta s·∫Ω **d·ª± ƒëo√°n t·ª´ ti·∫øp theo** c·ªßa vƒÉn b·∫£n ƒë√≥. üìù‚ú®  \n",
        "\n",
        "> **∆†, v·∫≠y nh√£n c·ªßa c√°c vƒÉn b·∫£n s·∫Ω ch√≠nh l√† t·ª´ ti·∫øp theo c·ªßa ch√∫ng √†?**  \n",
        "\n",
        "Yeah, ch√≠nh x√°c r·ªìi ƒë√≥! üåü"
      ],
      "metadata": {
        "id": "vld5yzwhOtHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **√îi, th·∫ø s·ªë l∆∞·ª£ng nh√£n c·ªßa m√¥ h√¨nh ch·∫≥ng ph·∫£i s·∫Ω r·∫•t kh·ªïng l·ªì hay sao Ôºà‚äôÔΩè‚äôÔºâ?**  \n",
        "\n",
        "Yeah, b·∫°n l·∫°i ƒëo√°n ƒë√∫ng r·ªìi. üéâ  \n",
        "\n",
        "S·ªë l∆∞·ª£ng nh√£n ch√≠nh l√† **s·ªë t·ª´ trong b·ªô t·ª´ ƒëi·ªÉn** √° =))  \n",
        "C√≥ khi n√≥ l√™n ƒë·∫øn t·∫≠n **10.000** √° ...(*Ôø£ÔºêÔø£)„Éé\n",
        "\n",
        "> **V·∫≠y ch√∫ng t·∫°o ra vƒÉn b·∫£n nh∆∞ th·∫ø n√†o?**  \n",
        "\n",
        "ƒê∆°n gi·∫£n th√¥i, t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh **l·∫∑p ƒëi l·∫∑p l·∫°i qu√° tr√¨nh d·ª± ƒëo√°n t·ª´ ti·∫øp theo**. üîÑ  \n",
        "Khi m·ªçi ng∆∞·ªùi d·ª± ƒëo√°n ƒë∆∞·ª£c m·ªôt t·ª´ m·ªõi, ch√∫ng ta s·∫Ω l·∫•y t·ª´ ƒë√≥ **k·∫øt h·ª£p l·∫°i v·ªõi vƒÉn b·∫£n ƒë·∫ßu v√†o** v√† ti·∫øp t·ª•c d·ª± ƒëo√°n t·ª´ k·∫ø ti·∫øp.  \n",
        "C·ª© ti·∫øn h√†nh nh∆∞ th·∫ø cho ƒë·∫øn khi h·∫øt s·ªë v√≤ng l·∫∑p ho·∫∑c ƒë·∫°t gi·ªõi h·∫°n s·ªë l∆∞·ª£ng t·ª´ d·ª± ƒëo√°n. üåü  \n",
        "\n",
        "N√≥ gi·ªëng h·ªát v·ªõi h√¨nh m√† t·ª•i m√¨nh ƒë√£ nh√¨n th·∫•y ·ªü ph·∫ßn ƒë·∫ßu ƒë√≥. üìÑ‚ú®  "
      ],
      "metadata": {
        "id": "3ORPU7SuQe2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![predictext](https://cgupta.tech/images/rnn_representative.png)"
      ],
      "metadata": {
        "id": "E_dLy8wRTkuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "·ªû ƒë√¢y, c√¢u vƒÉn ban ƒë·∫ßu c·ªßa ch√∫ng ta l√†: **\"the man is walking\"**, ph·∫ßn m√†u xanh d∆∞∆°ng l√† **c·ª≠a s·ªï tr∆∞·ª£t - window data** ƒë·ªÉ c·∫Øt l·∫•y d·ªØ li·ªáu ƒë·∫ßu v√†o v·ªõi ƒë·ªô d√†i t·ªëi ƒëa hi·ªán t·∫°i l√† **4 t·ª´**. Do ƒë√≥, **d·ªØ li·ªáu ƒë·∫ßu v√†o** c·ªßa ch√∫ng ta s·∫Ω l√† **\"the man is walking\"**.  \n",
        "\n",
        "***M·ªçi ng∆∞·ªùi nh·ªõ kƒ© ph·∫ßn c·ª≠a s·ªï tr∆∞·ª£t c·∫Øt l·∫•y d·ªØ li·ªáu ƒë·∫ßu v√†o gi√∫p m√¨nh nha.*** üìù  \n",
        "\n",
        "Qu√° tr√¨nh t·∫°o c√¢u vƒÉn, ·ªü ƒë√¢y m√¨nh cho s·ªë l∆∞·ª£ng t·ª´ t·∫°o ra l√† **4**, n√™n ch√∫ng ta s·∫Ω c√≥ **4 l·∫ßn l·∫∑p**.  \n",
        "\n",
        "**Step 1**: Nh·∫≠n ƒë·∫ßu v√†o l√† **\"the man is walking\"**, t·ª•i m√¨nh d·ª± ƒëo√°n ra ƒë∆∞·ª£c t·ª´ **\"down\"**.  \n",
        "\n",
        "**Step 2**: T·ª•i m√¨nh k·∫øt h·ª£p t·ª´ **\"down\"** v√†o chung v·ªõi vƒÉn b·∫£n ƒë·∫ßu v√†o l√∫c tr∆∞·ªõc l√† **\"the man is walking\"** th√†nh **\"the man is walking down\"**, sau ƒë√≥ **c·ª≠a s·ªï tr∆∞·ª£t v·ªõi k√≠ch th∆∞·ªõc l√† 4** s·∫Ω c·∫Øt l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o th√†nh **\"man is walking down\"** v√† d·ª± ƒëo√°n ra t·ª´ **\"the\"**.  \n",
        "\n",
        "**Step 3**: T∆∞∆°ng t·ª± nh∆∞ tr∆∞·ªõc, d·ªØ li·ªáu ƒë·∫ßu v√†o sau khi c·∫Øt l√† **\"is walking down the\"**, d·ª± ƒëo√°n ra t·ª´ **\"street\"**.  \n",
        "\n",
        "**Step 4**: D·ªØ li·ªáu ƒë·∫ßu v√†o l√† **\"walking down the street\"**, d·ª± ƒëo√°n ra d·∫•u **\".\"**.  \n",
        "\n",
        "V·∫≠y c√¢u cu·ªëi c√πng ch√∫ng ta d·ª± ƒëo√°n ra ƒë∆∞·ª£c s·∫Ω l√†:  \n",
        "> **\"the man is walking down the street .\"** üö∂‚Äç‚ôÇÔ∏è‚ú®  "
      ],
      "metadata": {
        "id": "_znzuVmHTl3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L√Ω thuy·∫øt ƒë·ªß nhi·ªÅu r·ªìi, t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh ƒëi v√†o th·ª±c h√†nh lu√¥n nha. „Éæ(‚Ä¢œâ‚Ä¢`)o"
      ],
      "metadata": {
        "id": "-FzYVdCkaLCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from datetime import timedelta\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "EYCnwYGAumKL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:02:37.494956Z",
          "iopub.execute_input": "2024-12-28T15:02:37.495228Z",
          "iopub.status.idle": "2024-12-28T15:02:37.499459Z",
          "shell.execute_reply.started": "2024-12-28T15:02:37.495206Z",
          "shell.execute_reply": "2024-12-28T15:02:37.498649Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o m·ªôt MirroredStrategy ƒë·ªÉ s·ª≠ d·ª•ng t·∫•t c·∫£ c√°c GPU c√≥ s·∫µn\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "metadata": {
        "id": "tTHJS8tl-ySf",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:02:37.500296Z",
          "iopub.execute_input": "2024-12-28T15:02:37.500517Z",
          "iopub.status.idle": "2024-12-28T15:02:37.516483Z",
          "shell.execute_reply.started": "2024-12-28T15:02:37.500487Z",
          "shell.execute_reply": "2024-12-28T15:02:37.515729Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu t·ªõi ph·∫ßn th·ª±c h√†nh b√™n d∆∞·ªõi m√¨nh xin ph√©p c√≥ l∆∞u √Ω nh·ªè: v√¨ th·ªùi gian hu·∫•n luy·ªán kh√° l√¢u n√™n  trong tr∆∞·ªùng h·ª£p c√°c b·∫°n kh√¥ng th·ªÉ hu·∫•n luy·ªán ƒë∆∞·ª£c c√≥ th·ªÉ t·∫£i c√°c file m√¥ h√¨nh m√† m√¨nh ƒë√£ hu·∫•n luy·ªán s·∫µn ƒë·ªÉ tr·∫£i nghi·ªám nha. M√¨nh ƒë√£ ƒëƒÉng d·ªØ li·ªáu l√™n **Kaggle** n√™n c√°c b·∫°n c√≥ th·ªÉ t·∫£i ·ªü ƒë√¢y [dataset_for_chap_8](https://www.kaggle.com/datasets/thnhkhangtrnhhunh/dataset-for-chap-8/data)"
      ],
      "metadata": {
        "id": "4vI-gu4NWMYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ti·∫øn h√†nh x·ª≠ l√Ω d·ªØ li·ªáu üõ†Ô∏è‚ú®"
      ],
      "metadata": {
        "id": "pxfK_EC-uep1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "D·ªØ li·ªáu m√† ch√∫ng ta s·∫Ω d√πng l√† ƒëo·∫°n th∆° d∆∞·ªõi ƒë√¢y nha."
      ],
      "metadata": {
        "id": "KWxk5JKrbCgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"\"\"In the town of Athy one Jeremy Lanigan\n",
        " Battered away til he hadnt a pound.\n",
        " His father died and made him a man again\n",
        " Left him a farm and ten acres of ground.\n",
        " He gave a grand party for friends and relations\n",
        " Who didnt forget him when come to the wall,\n",
        " And if youll but listen Ill make your eyes glisten\n",
        " Of the rows and the ructions of Lanigan‚Äôs Ball.\n",
        " Myself to be sure got free invitation,\n",
        " For all the nice girls and boys I might ask,\n",
        " And just in a minute both friends and relations\n",
        " Were dancing round merry as bees round a cask.\"\"\""
      ],
      "metadata": {
        "id": "bUVBfZv1cDnp",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ki·ªÉm tra c√∫ ph√°p ƒëo·∫°n th∆°\n",
        "print(repr(data))"
      ],
      "metadata": {
        "id": "Yjydxacbc1Wr",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# T·ª•i m√¨nh s·∫Ω coi m·∫´u d√≤ng trong ƒëo·∫°n th∆° l√† m·ªôt c√¢u v√† t√°ch ch√∫ng ra d·ª±a tr√™n d·∫•u xu·ªëng h√†ng \\n nha\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "# T·∫°o b·ªô t·ª´ ƒëi·ªÉn t·ª´ b·ªô d·ªØ li·ªáu c·ªßa ch√∫ng ta.\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "# Ki·ªÉm tra b·ªô t·ª´ ƒëi·ªÉn\n",
        "print(tokenizer.word_index)\n",
        "print(f\"S·ªë l∆∞·ª£ng t·ª´ trong b·ªô t·ª´ ƒëi·ªÉn l√†: {len(tokenizer.word_index)}\")"
      ],
      "metadata": {
        "id": "6zx47s04-fH_",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(tokenizer.word_index) + 1 # Th√™m 1 v√¥ ƒë·∫°i di·ªán cho ph·∫ßn token <padding>: 0"
      ],
      "metadata": {
        "id": "in8T7Aj3fWU6",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω t·ªõi v·ªõi ph·∫ßn x·ª≠ l√Ω d·ªØ li·ªáu hu·∫•n luy·ªán. üõ†Ô∏è  \n",
        "***M·ªçi ng∆∞·ªùi ch√∫ √Ω kƒ© ph·∫ßn n√†y, tr√°nh nh·∫ßm l·∫´n gi√∫p m√¨nh nha. ·ªû ph·∫ßn th·ª±c h√†nh n√†y, t·∫°m th·ªùi ch√∫ng ta s·∫Ω kh√¥ng s·ª≠ d·ª•ng c·ª≠a s·ªï tr∆∞·ª£t!***  \n",
        "\n",
        "ƒê·∫ßu ti√™n, ta ti·∫øn h√†nh m√£ h√≥a c√¢u t·ª´ d·ªØ li·ªáu vƒÉn b·∫£n sang chu·ªói d·∫°ng s·ªë. üî¢"
      ],
      "metadata": {
        "id": "0SExt7Nae8ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![encode](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_8/encode.png?raw=true)"
      ],
      "metadata": {
        "id": "TOjUe4FTGcWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ti·∫øp ƒë·∫øn, ch√∫ng ta s·∫Ω t√°ch chu·ªói th√†nh nhi·ªÅu chu·ªói con nh·ªè h∆°n v·ªõi ƒë·ªô d√†i chu·ªói tƒÉng d·∫ßn. ‚úÇÔ∏è  \n",
        "\n",
        "***Ch√∫ √Ω: M·ªçi ng∆∞·ªùi c·∫ßn ph·∫£i ph√¢n bi·ªát, hi·ªán t·∫°i ch√∫ng ta kh√¥ng s·ª≠ d·ª•ng c·ª≠a s·ªï tr∆∞·ª£t ·ªü ƒë√¢y nha!*** üßê  "
      ],
      "metadata": {
        "id": "zUtSQXAygX7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sub_sequences](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_8/sub_sequences.png?raw=true)"
      ],
      "metadata": {
        "id": "UhnbQnAmGfJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nh∆∞ m·ªçi ng∆∞·ªùi th·∫•y, t·ª´ m·ªôt chu·ªói ban ƒë·∫ßu ch√∫ng ta ƒë√£ t√°ch ra th√†nh 7 chu·ªói con, nh·ªù ƒë√≥ gia tƒÉng ƒë∆∞·ª£c s·ªë l∆∞·ª£ng d·ªØ li·ªáu. üå± C√°c chu·ªói con ƒë·ªÉ hu·∫•n luy·ªán n√†y c√≤n c√≥ t√™n g·ªçi kh√°c l√† **\"seed text - h·∫°t gi·ªëng vƒÉn b·∫£n\"**, kh·ªüi ngu·ªìn ƒë·ªÉ n·∫£y m·∫ßm, t·∫°o n√™n c√°c vƒÉn b·∫£n d·ª± ƒëo√°n sau n√†y.\n",
        "Vi·ªác chia c√°c chu·ªói con n√†y gi√∫p cho m√¥ h√¨nh c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c ng·ªØ c·∫£nh ·ªü nhi·ªÅu ƒë·ªô d√†i kh√°c nhau.üåü"
      ],
      "metadata": {
        "id": "r5SJT0Nzgtn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "  # M√£ h√≥a c√¢u (line) th√†nh chu·ªói s·ªë\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0] # V√¨ d·ªØ li·ªáu tr·∫£ v·ªÅ c·ªßa h√†m l√† d·∫°ng m·ªôt list n√™n ƒë·ªÉ l·∫•y ƒë∆∞·ª£c chu·ªói s·ªë ph·∫£i l·∫•y ph·∫ßn t·ª≠ 0 c·ªßa list\n",
        "  for i in range(1, len(token_list)):\n",
        "    # Ti·∫øn h√†nh t√°ch ra th√†nh t·ª´ng chu·ªói con\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Ki·ªÉm tra th·ª≠ 5 chu·ªói ƒë·∫ßu ti√™n\n",
        "for i in range(5):\n",
        "  print(input_sequences[i])"
      ],
      "metadata": {
        "id": "CAxkotOlhKwP",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "B√¢y gi·ªù ch√∫ng ta ti·∫øn h√†nh **padding** cho d·ªØ li·ªáu d·ª±a tr√™n ƒë·ªô d√†i c·ªßa c√¢u d√†i nh·∫•t. üõ†Ô∏è\n",
        "\n",
        "L√Ω do l√† b·ªüi v√¨ kh√¥ng c·ªë ƒë·ªãnh k√≠ch th∆∞·ªõc nh∆∞ **c·ª≠a s·ªï tr∆∞·ª£t**, d·ªØ li·ªáu gi·ªØa c√°c c√¢u c·ªßa ch√∫ng ta c√≥ k√≠ch th∆∞·ªõc ch√™nh l·ªách r·∫•t nhi·ªÅu. Ch√∫ng ta c·∫ßn **ƒë·ªìng d·∫°ng k√≠ch th∆∞·ªõc** ƒë·ªÉ ƒë∆∞a v√†o hu·∫•n luy·ªán m√¥ h√¨nh. üìè\n",
        "\n",
        "*üí° L∆∞u √Ω: Trong tr∆∞·ªùng h·ª£p n√†y, ch√∫ng ta s·∫Ω **padding ·ªü ƒë·∫ßu** (pre-padding) nha, ƒë·ªÉ t·ª´ c√≥ th·ªÉ ·∫£nh h∆∞·ªüng m·∫°nh h∆°n ƒë·∫øn t·ª´ d·ª± ƒëo√°n ph√≠a sau, gi·ªëng v·ªõi **kh·∫£ nƒÉng ·∫£nh h∆∞·ªüng c·ªßa tr√¨nh t·ª± c√°c t·ª´** m√† ch√∫ng ta ƒë√£ t√¨m hi·ªÉu ·ªü ch∆∞∆°ng 7.* üåü"
      ],
      "metadata": {
        "id": "OUdDON_DiOjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![padding_sequences](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_8/pad_sequences.png?raw=true)\n"
      ],
      "metadata": {
        "id": "Y0nsbaa5GjWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences_padded = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding=\"pre\"))\n",
        "\n",
        "# Ch·ªânh l·∫°i s·ªë l∆∞·ª£ng token v√¨ ƒë√£ th√™m token padding v√†o <pad>: 0\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Ki·ªÉm tra chu·ªói sau khi ƒë·ªám\n",
        "for i in range(5):\n",
        "  print(input_sequences_padded[i])"
      ],
      "metadata": {
        "id": "aEd3Sg6ukep8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "V·∫≠y l√† c√°c chu·ªói c·ªßa ch√∫ng ta ƒë√£ ƒë∆∞·ª£c **ƒë·ªám ƒë·∫ßy ƒë·ªß** v·ªõi k√≠ch th∆∞·ªõc l√† **10**. üéâ\n",
        "\n",
        "B√¢y gi·ªù, ch√∫ng ta s·∫Ω ti·∫øn h√†nh **chia d·ªØ li·ªáu** th√†nh hai ph·∫ßn:\n",
        "\n",
        "1. **D·ªØ li·ªáu hu·∫•n luy·ªán**: Ch√≠nh l√† c√°c t·ª´ trong chu·ªói **tr·ª´ t·ª´ cu·ªëi c√πng**.\n",
        "2. **Nh√£n**: L√† **t·ª´ cu·ªëi c√πng** c·ªßa m·ªói chu·ªói.\n",
        "\n",
        "Qu√° tr√¨nh n√†y s·∫Ω gi√∫p ch√∫ng ta c√≥ d·ªØ li·ªáu ph√π h·ª£p ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh d·ª± ƒëo√°n t·ª´ ti·∫øp theo. üöÄ"
      ],
      "metadata": {
        "id": "UwucCRjQnb2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![padding_sequences](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_8/x_labels.png?raw=true)"
      ],
      "metadata": {
        "id": "wth4hz87Gm_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = input_sequences_padded[:,:-1]\n",
        "labels = input_sequences_padded[:,-1]"
      ],
      "metadata": {
        "id": "RIKlNHE8qIFj",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "·ªû ƒë√¢y t·ª•i m√¨nh s·∫Ω √°p d·ª•ng m·ªôt **th·ªß thu·∫≠t nh·ªè** nh√©! üåü ƒê√¢y c≈©ng l√† c∆° h·ªôi ƒë·ªÉ ti·∫øp c·∫≠n m·ªôt lo·∫°i **loss function** kh√°c.\n",
        "\n",
        "Nh∆∞ tr∆∞·ªõc ƒë√¢y m√¨nh ƒë√£ ƒë·ªÅ c·∫≠p, c√≥ s·ª± kh√°c bi·ªát gi·ªØa **`sparse_categorical_crossentropy`** v√† **`categorical_crossentropy`**:\n",
        "\n",
        "- N·∫øu d·ªØ li·ªáu nh√£n l√† d·∫°ng **s·ªë index** (v√≠ d·ª•: `[0, 1, 2]`), ta s·∫Ω s·ª≠ d·ª•ng **`sparse_categorical_crossentropy`**.\n",
        "- Trong tr∆∞·ªùng h·ª£p n√†y, t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh **m√£ h√≥a nh√£n theo one-hot-encoding**, n√™n c·∫ßn s·ª≠ d·ª•ng **`categorical_crossentropy`**.\n",
        "\n",
        "### L∆∞u √Ω nh·ªè:\n",
        "- S·ª≠ d·ª•ng **index-based labels** (d·∫°ng s·ªë) c√≥ th·ªÉ **ti·∫øt ki·ªám b·ªô nh·ªõ h∆°n** v√¨ kh√¥ng c·∫ßn l∆∞u tr·ªØ to√†n b·ªô vector one-hot-encoding.\n",
        "- Tuy nhi√™n, v√¨ s√°ch ƒë√£ h∆∞·ªõng d·∫´n nh∆∞ v·∫≠y, t·ª•i m√¨nh c·ª© l√†m theo ƒë·ªÉ **l√†m quen v·ªõi c·∫£ hai c√°ch** nh√©! ‚ú®"
      ],
      "metadata": {
        "id": "-RUI2BuFqWqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![dataset](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_8/dataset.png?raw=true)"
      ],
      "metadata": {
        "id": "I9N7t-zZGpUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh m√£ h√≥a one-hot-encoding cho nh√£n\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "ys = to_categorical(labels, num_classes = total_words)"
      ],
      "metadata": {
        "id": "qhDwD98vrgMa",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ki·ªÉm tra l·∫°i d·ªØ li·ªáu c·ªßa ch√∫ng ta\n",
        "print(f\"Chu·ªói ƒë∆∞·ª£c m√£ h√≥a: {input_sequences[0]}\")\n",
        "print(f\"Chu·ªói x ƒë·ªÉ hu·∫•n luy·ªán: {xs[0]}\")\n",
        "print(f\"Nh√£n c·ªßa chu·ªói x, t·ª©c t·ª´ ti·∫øp theo: {labels[0]}\")\n",
        "print(f\"Nh√£n sau khi one-hot-encoding:\\n {ys[0]}\")"
      ],
      "metadata": {
        "id": "BCIMJdgIsKLo",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ti·∫øn h√†nh t·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh üöÄ"
      ],
      "metadata": {
        "id": "KfHd5Ahluajw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "·ªû ƒë√¢y t·ª•i m√¨nh s·∫Ω th·ª≠ kh·ªüi t·∫°o m·ªôt m√¥ h√¨nh ƒë∆°n gi·∫£n th√¥i nha.  \n",
        "\n",
        "S·ªë chi·ªÅu **Embedding** t·ª•i m√¨nh t·∫°m cho l√† 8 nha v√¨ k√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn, s·ªë l∆∞·ª£ng t·ª´ c≈©ng kh√° nh·ªè.  \n",
        "\n",
        "V·ªÅ tham s·ªë trong l·ªõp **BLSTM**, s·ªë ƒë∆°n v·ªã ·∫©n nh∆∞ ch∆∞∆°ng tr∆∞·ªõc t·ª•i m√¨nh ƒë·ªÉ theo s·ªë chi·ªÅu Embedding th√¨ ·ªü ƒë√¢y m√¨nh ƒë·ªÉ t∆∞∆°ng ƒë∆∞∆°ng v·ªõi ƒë·ªô d√†i c·ªßa chu·ªói ban ƒë·∫ßu tr·ª´ ƒëi 1 nha (v√¨ ch√∫ng ta ƒë√£ l·∫•y token cu·ªëi l√†m nh√£n n√™n tr·ª´ 1 ƒëi).  \n",
        "\n",
        "ƒê·∫ßu ra l·ªõp tuy·∫øn t√≠nh - **Dense**, th√¨ s·∫Ω b·∫±ng v·ªõi t·ªïng s·ªë l∆∞·ª£ng tokens hay s·ªë l∆∞·ª£ng t·ª´ v·ªõi 1 token padding. ‚ú®"
      ],
      "metadata": {
        "id": "cw23SIbMurtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X√¢y d·ª±ng ki·∫øn tr√∫c m√¥ h√¨nh\n",
        "model = Sequential([\n",
        "    Embedding(total_words, 8),\n",
        "    Bidirectional(LSTM(max_sequence_len-1)),\n",
        "    Dense(total_words, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "JC_DEmseu36E",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "B·ªüi v√¨ m√¥ h√¨nh ·ªü ƒë√¢y kh√° ƒë∆°n gi·∫£n v√† √≠t d·ªØ li·ªáu n√™n ch√∫ng ta ti·∫øn h√†nh hu·∫•n luy·ªán l√¢u h∆°n v·ªõi **s·ªë epoch l√† 15.000**."
      ],
      "metadata": {
        "id": "mYkUkiIwxEmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "history = model.fit(xs, ys, epochs=1500, verbose = 0)\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "pO0NF3m4w2xN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Th·ªùi gian hu·∫•n luy·ªán: {timedelta(seconds=end_time - start_time)} gi√¢y\")"
      ],
      "metadata": {
        "id": "CzLFU3K6Qg57",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì hu·∫•n luy·ªán\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_acc = history.history[\"accuracy\"]\n",
        "train_loss = history.history[\"loss\"]\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
        "axs[0].plot(train_acc)\n",
        "axs[0].set_title(\"Training Accuracy\")\n",
        "axs[1].plot(train_loss, color=\"orange\")\n",
        "axs[1].set_title(\"Training Loss\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XsNBEKtuxQAO",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha.\n",
        "\n",
        "![model](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_8/model.png?raw=true)"
      ],
      "metadata": {
        "id": "FPggWR4GHP1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(xs, ys)"
      ],
      "metadata": {
        "id": "HzWGVLLsy2Bq",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "0eC4JQ-N6qDQ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫£i l·∫°i model\n",
        "model = load_model(\"model.h5\")"
      ],
      "metadata": {
        "id": "7gY2QpWpFWO8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "K·∫øt qu·∫£ cu·ªëi c√πng t·ª•i m√¨nh ƒëo ƒë∆∞·ª£c s·∫Ω kho·∫£ng c·ª° 95%, ƒëi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† t·ª´ d·ª± ƒëo√°n ƒë∆∞·ª£c ti·∫øp theo c√≥ x√°c su·∫•t 95% gi·ªëng v·ªõi t·ª´ ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán b·ªüi chu·ªói tr∆∞·ªõc ƒë√≥.  \n",
        "\n",
        "***M·ªçi ng∆∞·ªùi l∆∞u √Ω gi√∫p m√¨nh: ·ªû ƒë√¢y s·ª≠ d·ª•ng ƒë·ªô ch√≠nh x√°c - accuracy ƒë·ªÉ ƒëo kh√¥ng th·∫≠t s·ª± hi·ªáu qu·∫£ ƒë·ªëi v·ªõi b√†i to√°n ng·ªØ nghƒ©a t·∫°o/sinh vƒÉn b·∫£n nh∆∞ n√†y. Cho ƒë·∫øn th·ªùi ƒëi·ªÉm hi·ªán t·∫°i t·ª•i m√¨nh h·ªçc, v·∫´n ch∆∞a c√≥ thang ƒëo n√†o ph√π h·ª£p tuy·ªát ƒë·ªëi cho b√†i to√°n.*** üåü"
      ],
      "metadata": {
        "id": "_O082PMny6Ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting the Next Word  \n",
        "### B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh d·ª± ƒëo√°n th·ª≠ m·ªôt t·ª´ ti·∫øp theo tr∆∞·ªõc nha.  \n",
        "\n",
        "VƒÉn b·∫£n m√¨nh ch·ªçn l√† **\"in the town of athy\"** n·∫±m ·ªü c√¢u ƒë·∫ßu ti√™n c·ªßa d·ªØ li·ªáu hu·∫•n luy·ªán nha. üåü  "
      ],
      "metadata": {
        "id": "gzTqlPpQ3Qq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text =  \"in the town of athy\""
      ],
      "metadata": {
        "id": "dVW2qQCv3rgx",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê·∫ßu ti√™n ta s·∫Ω ti·∫øn h√†nh tokenize cho chu·ªói ƒë√≥, sau ƒë√≥ th√¨ padding v√† ƒë∆∞a v√†o m√¥ h√¨nh"
      ],
      "metadata": {
        "id": "WebWVHuI3w-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre') # -1 v√†o max_sequence_len b·ªüi v√¨ chu·ªói n√†y kh√¥ng c√≥ nh√£n\n",
        "# Ti·∫øn h√†nh d·ª± ƒëo√°n\n",
        "predicted = model.predict(token_list, verbose=1)\n",
        "predicted_index = np.argmax(predicted, axis = -1)"
      ],
      "metadata": {
        "id": "jqRF78S_32r3",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o index to word ƒë·ªÉ chuy·ªÉn t·ª´ d·ªØ li·ªáu d·∫°ng s·ªë sang vƒÉn b·∫£n l·∫°i\n",
        "index_words ={}\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    index_words[index] = word\n",
        "\n",
        "# Chuy·ªÉn index d·ª± ƒëo√°n th√†nh d·∫°ng ch·ªØ\n",
        "predicted_word = index_words.get(predicted_index[0], \"\")\n",
        "\n",
        "print(f\"Chu·ªói ban ƒë·∫ßu: {seed_text}\")\n",
        "print(f\"T·ª´ d·ª± ƒëo√°n: '{predicted_word}' v·ªõi s√°c xu·∫•t {predicted[0][predicted_index[0]]*100:.2f}%\")"
      ],
      "metadata": {
        "id": "NfUxFC1q4RuN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "U·∫ßy ra t·ª´ \"one\" ƒë√∫ng v·ªõi c√¢u ƒë·∫ßu ti√™n trong d·ªØ li·ªáu hu·∫•n luy·ªán lu√¥n n√†y.\n",
        "> In the town of Athy one Jeremy Lanigan<br>\n",
        " Battered away til he hadnt a pound."
      ],
      "metadata": {
        "id": "6-gbSdiZ55xL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compounding Predictions to Generate Text  \n",
        "### B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh t·∫°o/sinh vƒÉn b·∫£n d·ª±a tr√™n workflow tr∆∞·ªõc ƒë√≥ t·ª•i m√¨nh ƒë·ªãnh nghƒ©a nha. üåü‚ú®üåà  \n",
        "\n",
        "***L∆∞u √Ω: ·ªû ƒë√¢y ch√∫ng ta ch·ªçn padding chu·ªói theo ƒë·ªô d√†i c√¢u d√†i nh·∫•t v√¨ ban ƒë·∫ßu khi d·ªØ li·ªáu hu·∫•n luy·ªán c≈©ng ƒë∆∞·ª£c l√†m nh∆∞ v·∫≠y ch·ª© ch∆∞a s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p c·ª≠a s·ªï tr∆∞·ª£t nha. ƒê·ªÉ m√† n√≥i m·ªçi ng∆∞·ªùi c≈©ng c√≥ th·ªÉ hi·ªÉu tr∆∞·ªùng h·ª£p n√†y k√≠ch th∆∞·ªõc c·ª≠a s·ªï tr∆∞·ª£t l√† ƒë·ªô d√†i c√¢u d√†i nh·∫•t c≈©ng ƒë∆∞·ª£c. T·ª´ ƒë√≥ c√°c chu·ªói kh√¥ng ƒë·ªß k√≠ch th∆∞·ªõc th√¨ s·∫Ω padding th√™m v√†o. üîÑüìè***\n",
        "\n",
        "Th√¥ng qua vi·ªác l·∫∑p ƒëi l·∫∑p l·∫°i qu√° tr√¨nh d·ª± ƒëo√°n t·ª´ ti·∫øp theo, k·∫øt h·ª£p l·∫°i v·ªõi d·ªØ li·ªáu ƒë·∫ßu v√†o r·ªìi d·ª± ƒëo√°n ti·∫øp ta s·∫Ω t·∫°o/sinh ra ƒë∆∞·ª£c ph·∫ßn ti·∫øp theo cho c√¢u vƒÉn. üìùüîÆ  \n",
        "\n",
        "·ªû ƒë√¢y m√¨nh s·ª≠ d·ª•ng d·ªØ li·ªáu ƒë·∫ßu v√†o ban ƒë·∫ßu l√† **\"sweet jeremy saw dublin\"** nha. T·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh d·ª± ƒëo√°n 10 t·ª´ ti·∫øp theo ph√≠a sau. üéØüìñ"
      ],
      "metadata": {
        "id": "O48-oBgP6KdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"sweet jeremy saw dublin\"\n",
        "predicted_text = seed_text\n",
        "n_words = 10\n",
        "\n",
        "for i in range(n_words):\n",
        "    token_list = tokenizer.texts_to_sequences([predicted_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=1)\n",
        "    predicted_index = np.argmax(predicted, axis=-1)\n",
        "    output_word = index_words.get(predicted_index[0], \"\")\n",
        "\n",
        "    print(f\"Step {i}:\")\n",
        "    print(f\"VƒÉn b·∫£n ƒë·∫ßu v√†o: {predicted_text}\")\n",
        "    print(f\"Chu·ªói m√£ h√≥a ƒë·∫ßu v√†o: {token_list}\")\n",
        "    print(f\"T·ª´ d·ª± ƒëo√°n: {output_word} v·ªõi x√°c su·∫•t {predicted[0][predicted_index[0]]*100:2f}\")\n",
        "    print(\"-\"*50)\n",
        "    predicted_text += \" \" + output_word\n",
        "\n",
        "print(predicted_text)\n"
      ],
      "metadata": {
        "id": "ugHAzgSL616W",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha:  \n",
        "\n",
        "> \"sweet jeremy saw dublin be sure of got free invitation lanigan lanigan invitation your\"  \n",
        "\n",
        "M·ªçi ng∆∞·ªùi c√≥ th·ªÉ th·∫•y c√†ng v·ªÅ sau th√¨ c√°c t·ª´ t·∫°o ra khi·∫øn c√¢u vƒÉn c√†ng tr·ªü n√™n v√¥ nghƒ©a h∆°n, th·∫≠m ch√≠ ƒë√¥i khi sai c·∫£ v·ªÅ m·∫∑t ng·ªØ ph√°p c·ªßa t·ª´. üòÖüìâ  \n",
        "\n",
        "> **V·∫≠y l·ªói n√†y do ƒë√¢u m√† ra?**  \n",
        "\n",
        "C√≥ 2 l√Ω do ch√≠nh ·∫£nh h∆∞·ªüng ƒë·∫øn vi·ªác n√†y l√†:  \n",
        "\n",
        "1. **D·ªØ li·ªáu hu·∫•n luy·ªán c·ªßa ch√∫ng ta qu√° nh·ªè** khi·∫øn m√¥ h√¨nh kh√¥ng th·ªÉ n·∫Øm b·∫Øt ƒë∆∞·ª£c nhi·ªÅu ng·ªØ c·∫£nh. üìö‚ùå  \n",
        "2. **Hi·ªáu ·ª©ng d√¢y chuy·ªÅn, c√°nh b∆∞·ªõm hay hi·ªáu ·ª©ng Domino.** Khi m·ªôt vi·ªác g√¨ ƒë√≥ x·∫£y ra th√¨ c√°c s·ª± vi·ªác sau ph·ª• thu·ªôc v√†o n√≥ s·∫Ω ch·ªãu ·∫£nh h∆∞·ªüng l·ªõn d·∫ßn l√™n. ·ªû ƒë√¢y, khi m·ªôt t·ª´ ƒë∆∞·ª£c d·ª± ƒëo√°n kh√¥ng t·ªët, c√°c t·ª´ ph√≠a sau n√≥ l·∫°i ƒë∆∞·ª£c d·ª± ƒëo√°n d·ª±a tr√™n n√≥ v√† c√°c t·ª´ ph√≠a tr∆∞·ªõc c≈©ng s·∫Ω tr·ªü n√™n t·ªá h∆°n. D·∫ßn d·∫ßn s·ª± t·ªá h·∫°i n√†y ng√†y m·ªôt l·ªõn d·∫ßn khi·∫øn cho c√°c t·ª´ n·ªëi v√†o c√¢u vƒÉn c√†ng v·ªÅ sau tr·ªü n√™n v√¥ nghƒ©a h∆°n r·∫•t l√† nhi·ªÅu. üîóüåÄ  \n",
        "\n",
        "C√≥ m·ªôt fact l√† v√†o nƒÉm 2016 ƒë√£ t·ª´ng c√≥ m·ªôt b·ªô phim vi·ªÖn t∆∞·ªüng [Sunspring](https://en.wikipedia.org/wiki/Sunspring) ƒë∆∞·ª£c t·∫°o ra b·ªüi AI. B·ªô phim n√†y kh√° bu·ªìn c∆∞·ªùi, ban ƒë·∫ßu n·ªôi dung v·∫´n ·ªïn cho ƒë·∫øn c√†ng v·ªÅ sau ch√∫ng l·∫°i tr·ªü n√™n kh√≥ hi·ªÉu ƒë√∫ng nghƒ©a ba ch·∫•m lu√¥n √Ω. üé•ü§ñ‚ú®"
      ],
      "metadata": {
        "id": "CD6R16wN3LNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extending the dataset  \n",
        "### B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω l√†m vi·ªác v·ªõi m√¥ h√¨nh v·ªõi b·ªô d·ªØ li·ªáu l·ªõn h∆°n nha.  \n",
        "\n",
        "·ªû ƒë√¢y theo t√°c gi·∫£ th√¨ b·ªô d·ªØ li·ªáu d∆∞·ªõi ƒë√¢y bao g·ªìm kho·∫£ng 1.700 v·ªÅ l·ªùi c√°c b√†i h√°t. V√¨ ƒë∆∞·ªùng d·∫´n trong s√°ch kh√¥ng th·ªÉ s·ª≠ d·ª•ng ƒë∆∞·ª£c n·ªØa n√™n t·ª•i m√¨nh s·∫Ω t·∫£i d·ªØ li·ªáu t·ª´ Kaggle nha. üé∂üì•  "
      ],
      "metadata": {
        "id": "RnbyzGdC-riZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jamzhu/irishlyricseof\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "GS4Qi4i0_CGA",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Li·ªát k√™ c√°c file b√™n trong th∆∞ m·ª•c\n",
        "import os\n",
        "for f in os.listdir(path):\n",
        "  print(f)"
      ],
      "metadata": {
        "id": "QnMJvtpT_GAc",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh t·∫£i b·ªô d·ªØ li·ªáu\n",
        "# data = open(\"/kaggle/input/irishlyricseof/irish-lyrics-eof.txt\", \"r\").read()\n",
        "data = open(os.path.join(path, \"irish-lyrics-eof.txt\"), \"r\").read()\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "# In th·ª≠ 5 h√†ng ƒë·∫ßu ti√™n ra\n",
        "for i in range(5):\n",
        "  print(repr(corpus[i]))"
      ],
      "metadata": {
        "id": "exeWRN8l_XlM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T07:59:09.867523Z",
          "iopub.execute_input": "2024-12-28T07:59:09.867865Z",
          "iopub.status.idle": "2024-12-28T07:59:09.891653Z",
          "shell.execute_reply.started": "2024-12-28T07:59:09.867835Z",
          "shell.execute_reply": "2024-12-28T07:59:09.891023Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T07:59:18.449231Z",
          "iopub.execute_input": "2024-12-28T07:59:18.449612Z",
          "iopub.status.idle": "2024-12-28T07:59:18.455081Z",
          "shell.execute_reply.started": "2024-12-28T07:59:18.449578Z",
          "shell.execute_reply": "2024-12-28T07:59:18.454345Z"
        },
        "id": "4AjLmmzyGLrh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh tokenize d·ªØ li·ªáu\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1 # Th√™m m·ªôt cho token padding sau n√†y\n",
        "print(f\"T·ªïng s·ªë l∆∞·ª£ng t·ª´: {total_words}\")\n",
        "print(f\"B·ªô t·ª´ ƒëi·ªÉn t·ª´ v·ª±ng: {tokenizer.word_index}\")"
      ],
      "metadata": {
        "id": "fBR3Ohcf_4HD",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o b·ªô t·ª´ ƒëi·ªÉn chuy·ªÉn d·ªØ li·ªáu s·ªë th√†nh ch·ªØ l·∫°i\n",
        "index_words ={}\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    index_words[index] = word\n",
        "\n",
        "# Ti·∫øn h√†nh t·∫°o c√°c seed text hay chu·ªói con\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)-1):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Ki·ªÉm tra 5 chu·ªói m√£ h√≥a s·ªë ƒë·∫ßu ti√™n\n",
        "for i in range(5):\n",
        "  print(input_sequences[i])\n"
      ],
      "metadata": {
        "id": "9FARlEG1Anbb",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh padding cho d·ªØ li·ªáu\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "print(f\"ƒê·ªô d√†i chu·ªói d√†i nh·∫•t: {max_sequence_len}\")\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "# In th·ª≠ 5 chu·ªói ƒë·∫ßu ti√™n\n",
        "for i in range(5):\n",
        "  print(input_sequences[i])"
      ],
      "metadata": {
        "id": "nMe2sgSUBlmN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh chia d·ªØ li·ªáu hu·∫•n luy·ªán v√† nh√£n\n",
        "xs = input_sequences[:,:-1]\n",
        "labels = input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "TYB7Zl9vCFph",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Thi·∫øt l·∫≠p m√¥ h√¨nh\n",
        "model1 = Sequential([\n",
        "    Embedding(total_words, 8),\n",
        "    Bidirectional(LSTM(max_sequence_len-1)),\n",
        "    Dense(total_words, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model1.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "gSU79wB_CMV7",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "history1 = model1.fit(xs, labels, epochs=1000, verbose = 0)\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "1ZO2GYa3CrXk",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"model1.h5\")"
      ],
      "metadata": {
        "id": "_Kz5jVw561Gr",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Th·ªùi gian hu·∫•n luy·ªán: {timedelta(seconds=end_time-start_time)}\")"
      ],
      "metadata": {
        "id": "7ZaULiFaibUA",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì qu√° tr√¨nh hu·∫•n luy·ªán\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
        "train_acc = history1.history[\"accuracy\"]\n",
        "train_loss = history1.history[\"loss\"]\n",
        "axs[0].plot(train_acc)\n",
        "axs[0].set_title(\"Training Accuracy\")\n",
        "axs[1].plot(train_loss, color=\"orange\")\n",
        "axs[1].set_title(\"Training Loss\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AeJHizKpCwFH",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha.\n",
        "\n",
        "![model1](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_8/model1.png?raw=true)"
      ],
      "metadata": {
        "id": "RrohSGgpJ91A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(xs,labels)"
      ],
      "metadata": {
        "id": "ffBTpv2Qnz5W",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫£i l·∫°i m√¥ h√¨nh\n",
        "model1 = load_model(\"model1.h5\")"
      ],
      "metadata": {
        "id": "MIwiMg7aGh-0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "U·∫ßy, v·∫≠y l√† v·ªõi b·ªô d·ªØ li·ªáu n√†y, ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p hu·∫•n luy·ªán ƒë·∫°t ƒë∆∞·ª£c l√† kho·∫£ng 60%. üéâ\n",
        "\n",
        "B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh d·ª± ƒëo√°n th·ª≠ v·ªõi c√°c v·∫ø tr∆∞·ªõc ƒë√≥ nha. üîç‚ú®"
      ],
      "metadata": {
        "id": "xdfhGOIflUV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D·ª± ƒëo√°n m·ªôt t·ª´\n",
        "seed_text = \"in the town of athy\"\n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre') # -1 v√†o max_sequence_len b·ªüi v√¨ chu·ªói n√†y kh√¥ng c√≥ nh√£n\n",
        "# Ti·∫øn h√†nh d·ª± ƒëo√°n\n",
        "predicted = model1.predict(token_list, verbose=1)\n",
        "predicted_index = np.argmax(predicted, axis = -1)\n",
        "predicted_word = index_words.get(predicted_index[0], \"\")\n",
        "\n",
        "print(f\"T·ª´ d·ª± ƒëo√°n l√†: '{predicted_word}' v·ªõi x√°c su·∫•t {predicted[0][predicted_index[0]]*100:.2f}%\")"
      ],
      "metadata": {
        "id": "BEiQdO-tmmdW",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "·ªû ƒë√¢y k·∫øt qu·∫£ m√¨nh ra ƒë∆∞·ª£c l√†:  \n",
        "> T·ª´ d·ª± ƒëo√°n l√†: 'one' v·ªõi x√°c su·∫•t 67.04% ‚ú®  \n",
        "\n",
        "M·ªçi ng∆∞·ªùi c√≥ th·ªÉ ra k·∫øt qu·∫£ kh√°c nha, ƒëi·ªÅu n√†y ph·ª• thu·ªôc v√†o tr·ªçng s·ªë c·ªßa m√¥ h√¨nh m√† tr·ªçng s·ªë c·ªßa m·ªói m√¥ h√¨nh khi kh·ªüi t·∫°o l√† ng·∫´u nhi√™n, kh√¥ng gi·ªëng nhau n√™n k·∫øt qu·∫£ cu·ªëi c≈©ng v·∫≠y. Mi·ªÖn sao √Ω nghƒ©a c√¢u vƒÉn hay c√°c t·ª´ c√≥ ph·∫ßn li√™n k·∫øt nhau h·ª£p l√Ω l√† ok r·ªìi. üåü  \n",
        "\n",
        "T·ª•i m√¨nh s·∫Ω d·ª± ƒëo√°n ti·∫øp v·ªõi c·ª•m **‚Äúsweet jeremy saw dublin‚Äù**. üöÄ"
      ],
      "metadata": {
        "id": "KZZxqUJgoD_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D·ª± ƒëo√°n m·ªôt chu·ªói\n",
        "seed_text = \"sweet jeremy saw dublin\"\n",
        "num_words = 10\n",
        "predicted_text = seed_text\n",
        "for i in range(num_words):\n",
        "  token_list = tokenizer.texts_to_sequences([predicted_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted = model1.predict(token_list, verbose=1)\n",
        "  predicted_index = np.argmax(predicted, axis=-1)\n",
        "  output_word = index_words.get(predicted_index[0], \"\")\n",
        "\n",
        "  print(f\"Step {i}:\")\n",
        "  print(f\"VƒÉn b·∫£n ƒë·∫ßu v√†o: {predicted_text}\")\n",
        "  print(f\"Chu·ªói m√£ h√≥a ƒë·∫ßu v√†o: {token_list[0]}\")\n",
        "  print(f\"T·ª´ d·ª± ƒëo√°n: {output_word} v·ªõi x√°c su·∫•t {predicted[0][predicted_index[0]]*100:2f}%\")\n",
        "  print(\"-\"*50)\n",
        "  predicted_text += \" \" + output_word\n"
      ],
      "metadata": {
        "id": "4sGNrH4a3rA4",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"VƒÉn b·∫£n sinh ra: '{predicted_text}'\")"
      ],
      "metadata": {
        "id": "7n3i2V3Osxlq",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh:  \n",
        "> VƒÉn b·∫£n sinh ra: 'sweet jeremy saw dublin will you save that if it was a small thorn'‚ú®  \n",
        "\n",
        "C√≥ v·∫ª l√† ch√∫ng ƒë√£ ·ªïn h∆°n r·ªìi ha, sai s√≥t th√¨ t·∫•t nhi√™n v·∫´n c√≥ nh∆∞ng ng·ªØ nghƒ©a c·∫•u tr√∫c ƒë√£ ·ªïn h∆°n t√≠ r·ªìi. üåü B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω ƒëi th·ª≠ th√™m nhi·ªÅu c√°ch n·ªØa ƒë·ªÉ tƒÉng ƒë·ªô hi·ªáu qu·∫£ l√™n h∆°n nha. üöÄ  "
      ],
      "metadata": {
        "id": "_NcgUOcUs5gb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing the Modle Architecture\n",
        "### Tr∆∞·ªõc m·∫Øt th√¨ t·ª•i m√¨nh s·∫Ω th·ª≠ thay ƒë·ªïi ki·∫øn tr√∫c m√¥ h√¨nh xem sao."
      ],
      "metadata": {
        "id": "cqKd6g6HuzVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2= Sequential([\n",
        "    Embedding(total_words, 8),\n",
        "    Bidirectional(LSTM(max_sequence_len-1, return_sequences=True)),\n",
        "    Bidirectional(LSTM(max_sequence_len-1)),\n",
        "    Dense(total_words, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model2.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "_Zj5H1WiuacY",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh hu·∫•n luy·ªán\n",
        "start_time = time.time()\n",
        "history2 = model2.fit(xs, labels, epochs = 1000, verbose = 0)\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "GntMGZGKvoD7",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save(\"model2.h5\")"
      ],
      "metadata": {
        "id": "y40Bspoj7Dll",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Th·ªùi gian hu·∫•n luy·ªán m√¥ h√¨nh: {timedelta(seconds=end_time - start_time)}\")"
      ],
      "metadata": {
        "id": "5YizHpfmv3TX",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì qu√° tr√¨nh hu·∫•n luy·ªán\n",
        "train_acc = history2.history[\"accuracy\"]\n",
        "train_loss = history2.history[\"loss\"]\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
        "axs = axs.flatten()\n",
        "axs[0].plot(train_acc)\n",
        "axs[0].set_title(\"Training Accuracy\")\n",
        "axs[1].plot(train_loss, color=\"orange\")\n",
        "axs[1].set_title(\"Training Loss\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UN-m48Hlv_iw",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha.\n",
        "\n",
        "![model2](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_8/model2.png?raw=true)"
      ],
      "metadata": {
        "id": "a2jCuS52KrYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bi·ªÉu ƒë·ªì v·∫´n kh√° nhi·ªÖu nh·ªâ, s·ª± bi·∫øn ƒë·ªông l√™n xu·ªëng v·∫´n xu·∫•t hi·ªán nhi·ªÅu cho th·∫•y ch√∫ng v·∫´n g·∫∑p l·ªói nhi·ªÅu. M·ªôt trong nh·ªØng nguy√™n nh√¢n ƒë·∫øn t·ª´ vi·ªác ng·ªØ c·∫£nh c√°c c√¢u kh√¥ng c√≥ s·ª± li√™n k·∫øt v·ªõi nhau."
      ],
      "metadata": {
        "id": "3kKLCK2mK80P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ƒê√°nh gi√° m√¥ h√¨nh\n",
        "model2.evaluate(xs, labels)"
      ],
      "metadata": {
        "id": "4C8952SpwUqb",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫£i l·∫°i m√¥ h√¨nh\n",
        "model2 = load_model(\"model2.h5\")"
      ],
      "metadata": {
        "id": "G_RapNTYGs-P",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "T·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh d·ª± ƒëo√°n l·∫°i v·ªõi c√°c c√¢u tr∆∞·ªõc ƒë√≥"
      ],
      "metadata": {
        "id": "DLXe5_SSwiVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D·ª± ƒëo√°n m·ªôt t·ª´\n",
        "seed_text = \"in the town of athy\"\n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre') # -1 v√†o max_sequence_len b·ªüi v√¨ chu·ªói n√†y kh√¥ng c√≥ nh√£n\n",
        "# Ti·∫øn h√†nh d·ª± ƒëo√°n\n",
        "predicted = model2.predict(token_list, verbose=1)\n",
        "predicted_index = np.argmax(predicted, axis = -1)\n",
        "predicted_word = index_words.get(predicted_index[0], \"\")\n",
        "\n",
        "print(f\"T·ª´ d·ª± ƒëo√°n l√†: '{predicted_word}' v·ªõi x√°c su·∫•t {predicted[0][predicted_index[0]]*100:.2f}%\")"
      ],
      "metadata": {
        "id": "vYtBRNkTwZv2",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "K·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha.\n",
        "\n",
        "> T·ª´ d·ª± ƒëo√°n l√†: 'been' v·ªõi x√°c su·∫•t 33.22%"
      ],
      "metadata": {
        "id": "g8sil5NBMk7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D·ª± ƒëo√°n m·ªôt t·ª´\n",
        "seed_text = \"sweet jeremy saw dublin\"\n",
        "num_words = 10\n",
        "predicted_text = seed_text\n",
        "for i in range(num_words):\n",
        "  token_list = tokenizer.texts_to_sequences([predicted_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted = model2.predict(token_list, verbose=1)\n",
        "  predicted_index = np.argmax(predicted, axis=-1)\n",
        "  output_word = index_words.get(predicted_index[0], \"\")\n",
        "\n",
        "  print(f\"Step {i}:\")\n",
        "  print(f\"VƒÉn b·∫£n ƒë·∫ßu v√†o: {predicted_text}\")\n",
        "  print(f\"Chu·ªói m√£ h√≥a ƒë·∫ßu v√†o: {token_list[0]}\")\n",
        "  print(f\"T·ª´ d·ª± ƒëo√°n: {output_word} v·ªõi x√°c su·∫•t {predicted[0][predicted_index[0]]*100:2f}%\")\n",
        "  print(\"-\"*50)\n",
        "  predicted_text += \" \" + output_word\n"
      ],
      "metadata": {
        "id": "E9nkVt5Kwo2o",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"VƒÉn b·∫£n sinh ra: '{predicted_text}'\")"
      ],
      "metadata": {
        "id": "UBh1yyAOHlZ6",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "K·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha.\n",
        "\n",
        "> VƒÉn b·∫£n sinh ra: 'sweet jeremy saw dublin wandered for the rocky sentry be their lips lays the'"
      ],
      "metadata": {
        "id": "foPFTeL2MPeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving the Data  \n",
        "### B√¢y gi·ªù t·ª•i m√¨nh ti·∫øn h√†nh th·ª≠ c√°ch c·∫£i thi·ªán d·ªØ li·ªáu ƒë·∫ßu v√†o ƒë·ªÉ c·∫£i ti·∫øn m√¥ h√¨nh nha, tƒÉng ƒë·ªô hi·ªáu qu·∫£ nha. ‚ú®  \n",
        "\n",
        "S·ªü dƒ© m·ªçi ng∆∞·ªùi th·∫•y ƒë∆∞·ªùng **train_accuracy** nhi·ªÖu v·∫≠y l√† v√¨ d·ªØ li·ªáu v·∫´n thi·∫øu ƒëi ph·∫ßn n√†o ƒë√≥ s·ª± li√™n k·∫øt ng·ªØ c·∫£nh m·∫°ch l·∫°c. üåê  \n",
        "\n",
        "> **V·∫≠y nguy√™n nh√¢n do ƒë√¢u m√† ra?**  \n",
        "\n",
        "Ch√≠nh l√† do c√°ch ti·∫øp c·∫≠n, chi·∫øn l∆∞·ª£c chia, x·ª≠ l√Ω d·ªØ li·ªáu c·ªßa ch√∫ng ta tr∆∞·ªõc ƒë√≥. Trong m·ªôt b√†i h√°t th√¨ c√°c c√¢u h√°t ƒë·ªÅu c√≥ s·ª± li√™n k·∫øt ng·ªØ c·∫£nh v·ªõi nhau, ƒë√≥ c≈©ng l√† c√°ch m√† con ng∆∞·ªùi ti·∫øp thu. üé∂ Tuy nhi√™n khi ƒë∆∞a d·ªØ li·ªáu v√†o hu·∫•n luy·ªán cho m√¥ h√¨nh, ch√∫ng ta ƒë√£ coi **m·ªói c√¢u h√°t l√† m·ªôt d√≤ng ƒë·ªôc l·∫≠p** v√† ti·∫øn h√†nh chia chu·ªói con. Ch√≠nh ƒëi·ªÅu n√†y ƒë√£ l√†m cho c√°c c√¢u h√°t tr·ªü n√™n m·∫•t k·∫øt n·ªëi ng·ªØ c·∫£nh v·ªõi nhau. üîó  \n",
        "\n",
        "> **Ok, x√°c ƒë·ªãnh ƒë∆∞·ª£c g·ªëc v·∫•n ƒë·ªÅ r·ªìi v·∫≠y ch√∫ng ta s·∫Ω l√†m g√¨ ti·∫øp theo ƒë√¢y?**  \n",
        "\n",
        "C√¢u tr·∫£ l·ªùi l√† l√†m sao cho c√°c chu·ªói vƒÉn b·∫£n hu·∫•n luy·ªán c√≥ ch·ª©a m·ªôt ph·∫ßn c·ªßa c√¢u tr∆∞·ªõc v√† c√¢u sau, t·ª´ ƒë√≥ gi·ªØa c√°c c√¢u s·∫Ω c√≥ s·ª± li√™n k·∫øt v·ªõi nhau. üß©  \n",
        "\n",
        "B√¢y gi·ªù thay v√¨ ƒë·ªÉ c√°c c√¢u trong b√†i h√°t th√†nh m·ªôt h√†ng ƒë·ªôc l·∫≠p, ch√∫ng ta s·∫Ω ti·∫øn h√†nh **gom t·∫•t c·∫£ c√°c c√¢u ƒë√≥ l·∫°i v·ªÅ chung m·ªôt h√†ng. Ch√∫ng ta s·∫Ω kh√¥ng chia theo k√Ω t·ª± xu·ªëng h√†ng \"\\n\" n·ªØa m√† l√† theo d·∫•u kho·∫£ng c√°ch**  üöÄ  \n",
        "\n",
        "**V·∫≠y workflow c·ªßa ch√∫ng ta s·∫Ω nh∆∞ sau:**\n",
        "\n",
        "**1. Chia c√°c c√¢u d·ª±a tr√™n c·ª≠a s·ªï tr∆∞·ª£t:** Chia ƒëo·∫°n vƒÉn th√†nh danh s√°ch c√°c t·ª´, sau ƒë√≥ d√πng c·ª≠a s·ªï tr∆∞·ª£t ƒë·ªÉ t·∫°o ra c√°c c√¢u hay chu·ªói con. Qua ƒë√≥ ta c√≥ th·ªÉ gi·ªØ ƒë∆∞·ª£c s·ª± li√™n k·∫øt ng·ªØ c·∫£nh c·ªßa c√°c c√¢u v·ªõi nhau.\n",
        "\n",
        "**2. Ti·∫øn h√†nh chia c√°c chu·ªói con t·ª´ c√°c chu·ªói ƒë√£ chia tr∆∞·ªõc ƒë√≥:** l√†m gi·ªëng nh∆∞ c√°ch ban ƒë√¢u tuy nhi√™n thay v√¨ d·ªØ li·ªáu c·ªßa ch√∫ng ta l√† c√°c c√¢u ƒë·ªôc l·∫≠p th√¨ gi·ªù l√† c√°c c√¢u ƒë√£ ƒë∆∞·ª£c t·∫°o ra ·ªü b∆∞·ªõc 1."
      ],
      "metadata": {
        "id": "LNNKR4SZB9VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ki·ªÉm tra l·∫°i d·ªØ li·ªáu\n",
        "# print(repr(data))"
      ],
      "metadata": {
        "id": "otAJ6Gxc5nlv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ti·∫øn h√†nh chia c√°c c√¢u, chu·ªói d·ª±a tr√™n c·ª≠a s·ªï tr∆∞·ª£t"
      ],
      "metadata": {
        "id": "-BRk1caBJyXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re\n",
        "# Chia theo kho·∫£ng c√°ch thay v√¨ k√≠ t·ª± xu·ªëng h√†ng \"\\n\"\n",
        "window_size = 6\n",
        "\n",
        "# Ti·∫øn h√†nh l·∫•y chu√¥i c√°c t·ª´ trong vƒÉn b·∫£n\n",
        "corpus = data.lower()\n",
        "words = corpus.split(\" \")\n",
        "\n",
        "# Ti·∫øn h√†nh chia c√°c c√¢u (chu·ªói) d·ª±a tr√™n c·ª≠a s·ªï tr∆∞·ª£t\n",
        "range_size = len(words) - window_size + 1\n",
        "\n",
        "input_sentences = []\n",
        "for i in range(range_size):\n",
        "  input_sentences.append(\" \".join(words[i:i+window_size]))\n",
        "\n",
        "\n",
        "# Ki·ªÉm tra 5 c√¢u (chu·ªói) ƒë·∫ßu ti√™n\n",
        "for i in range(5):\n",
        "  print(repr(input_sentences[i]))"
      ],
      "metadata": {
        "id": "AWF2E1v958Eh",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C√°c c√¢u ·ªü chi·∫øn l∆∞·ª£c chia d·ªØ li·ªáu c≈©:**\n",
        ">come all ye maidens young and fair   \n",
        "and you that are blooming in your prime   \n",
        "always beware and keep your garden fair   \n",
        "let no man steal away your thyme   \n",
        "for thyme it is a precious thing   \n",
        "\n",
        "\n",
        "**C√°c c√¢u chia theo ph∆∞∆°ng ph√°p c·ª≠a s·ªï tr∆∞·ª£t:**\n",
        ">come all ye maidens young and   \n",
        "all ye maidens young and fair\\nand   \n",
        "ye maidens young and fair\\nand you   \n",
        "maidens young and fair\\nand you that    \n",
        "young and fair\\nand you that are"
      ],
      "metadata": {
        "id": "QnI46rvLt2Vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B√¢y gi·ªù t·ª•i m√¨nh ƒë·∫øn v·ªõi b∆∞·ªõc 2, ti·∫øn h√†nh m√£ h√≥a v√† chia chu·ªói con nha."
      ],
      "metadata": {
        "id": "zmh8M-COJrWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(input_sentences)\n",
        "\n",
        "sub_sequences = []\n",
        "# Ti·∫øn h√†nh m√£ h√≥a v√† chia chu·ªói con\n",
        "for sentence in input_sentences:\n",
        "  token_list = tokenizer.texts_to_sequences([sentence])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    sub_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Ki·ªÉm tra 5 chu·ªói ƒë·∫ßu ti√™n\n",
        "for i in range(5):\n",
        "  print(sub_sequences[i])"
      ],
      "metadata": {
        "id": "9S6aJ6JGEp6N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ki·ªÉm tra k√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn\n",
        "print(f\"T·ªïng s·ªë l∆∞·ª£ng t·ª´: {len(tokenizer.word_index)}\")\n",
        "print(f\"B·ªô t·ª´ ƒëi·ªÉn t·ª´ v·ª±ng: {tokenizer.word_index}\")"
      ],
      "metadata": {
        "id": "EFgORcrIHB10",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o t·ª´ ƒëi·ªÉn chuy·ªÉn s·ªë th√†nh t·ª´\n",
        "index_words ={}\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    index_words[index] = word"
      ],
      "metadata": {
        "id": "1_sA4k2iAxvj",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "·ªû ƒë√¢y c√≥ m·ªôt l∆∞u √Ω nh·ªè: v√¨ b·∫£n th√¢n tokenizer ƒë√£ c√≥ s·∫µn m·ªôt b·ªô l·ªçc ƒë·ªÉ c√°c k√≠ t·ª± ƒë·∫∑c bi·ªát n√™n c√°c t·ª´ n·ªëi li·ªÅn b·ªüi k√≠ t·ª± ƒë·∫∑c bi·ªát (v√≠ d·ª•: \"mother-in-law\" s·∫Ω b·ªã chuy·ªÉn th√†nh \"mother in law\"). Do ƒë√≥ s·∫Ω c√≥ m·ªôt s·ªë chu·ªói c√≥ k√≠ch th∆∞·ªõc l·ªõn h∆°n so v·ªõi c·ª≠a s·ªï tr∆∞·ª£t. Ta s·∫Ω ti·∫øn h√†nh t√≠nh l·∫°i ƒë·ªô d√†i chu·ªói d√†i nh·∫•t."
      ],
      "metadata": {
        "id": "5l6lBGl4HNUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max([len(x) for x in sub_sequences])\n",
        "print(f\"ƒê·ªô d√†i chu·ªói d√†i nh·∫•t: {max_sequence_len}\")"
      ],
      "metadata": {
        "id": "4NXxTxfyHM1w"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "K·∫øt qu·∫£ l√†:\n",
        "> ƒê·ªô d√†i chu·ªói d√†i nh·∫•t: 22\n",
        "\n",
        "Nh∆∞ ch√∫ng m√¨nh ƒë√£ d·ª± ƒëo√°n nh∆∞ng kh√¥ng ng·ªù k√≠ch th∆∞·ªõc n√≥ c√≥ th·ªÉ tƒÉng l√™n nhi·ªÅu v·∫≠y."
      ],
      "metadata": {
        "id": "5ExmeFzg9qvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ki·ªÉm tra 5 chu·ªói c√≥ ƒë·ªô d√†i l·ªõn h∆°n c·ª≠a s·ªï tr∆∞·ª£t.\n",
        "sequences_higher_than_window = []\n",
        "for i in range(len(sub_sequences)):\n",
        "  if len(sub_sequences[i]) > window_size:\n",
        "    sequences_higher_than_window.append(sub_sequences[i])\n",
        "\n",
        "for i in range(5):\n",
        "  print(sequences_higher_than_window[i])"
      ],
      "metadata": {
        "id": "D3zOa44BIbPr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh padding ƒë·ªÉ t·∫•t c·∫£ chu·ªói c√≥ c√πng k√≠ch th∆∞·ªõc, ƒë·ªô d√†i nha."
      ],
      "metadata": {
        "id": "PGEiY9D1IxOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = np.array(pad_sequences(sub_sequences, maxlen=max_sequence_len, padding=\"pre\"))\n",
        "\n",
        "# Chia d·ªØ li·ªáu x v√† labels ƒë·ªÉ hu·∫•n luy·ªán.\n",
        "xs = input_sequences[:,:-1]\n",
        "labels = input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "QQ0JH5xpI6bS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ti·∫øn h√†nh t·∫°o dataset ƒë·ªÉ t·ªëi ∆∞u h√≥a d·ªØ li·ªáu ƒë·∫©y v√†o qu√° tr√¨nh hu·∫•n luy·ªán"
      ],
      "metadata": {
        "id": "TH_4wehACKF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o datagen ƒë·ªÉ x·ªß l√Ω nhanh, t·ªëi ∆∞u h√≥a qu√° tr√¨nh hu·∫•n luy·ªán h∆°n\n",
        "# T·∫°o ƒë·ªëi t∆∞·ª£ng Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((xs, labels))\n",
        "\n",
        "# T·ªëi ∆∞u Dataset v·ªõi shuffle, batch v√† prefetch\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "dataset = (\n",
        "    dataset\n",
        "    .cache(\"train_cache.tfdata\")    # Thay v√¨ l∆∞u d·ªØ li·ªáu v√†o ram th√¨ l∆∞u h·∫≥n v√†o disk\n",
        "    .shuffle(buffer_size=1000)      # Tr·ªôn d·ªØ li·ªáu\n",
        "    .batch(32)                      # Chia batch (batch_size=32)\n",
        "    .prefetch(buffer_size=AUTOTUNE) # T·∫£i tr∆∞·ªõc d·ªØ li·ªáu\n",
        ")"
      ],
      "metadata": {
        "id": "9E1MISaHXoem",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "M√¨nh s·∫Ω ti·∫øn h√†nh ƒë·ªãnh nghƒ©a ki·∫øn tr√∫c m√¥ h√¨nh theo ƒë√∫ng l·∫ßn th·ª≠ c·ªßa t√°c gi·∫£, m·ªçi ng∆∞·ªùi c√≥ th·ªÉ linh ho·∫°t thay ƒë·ªïi c√°c si√™u tham s·ªë li√™n t·ª•c ƒë·ªÉ c·∫£i thi·ªán nha.  \n",
        "\n",
        "T√°c gi·∫£ sau khi th·ª≠ nhi·ªÅu l·∫ßn th√¨ c√≥ ƒë·ªÅ xu·∫•t:  \n",
        "- **window_size**: 6  \n",
        "- **s·ªë chi·ªÅu embedding**: 16  \n",
        "- **s·ªë unit trong LSTMs**: 32  \n",
        "- **tƒÉng t·ªëc ƒë·ªô h·ªçc-learning rate l√™n**: t√°c gi·∫£ kh√¥ng n√≥i r√µ n√™n m√¨nh t·∫°m l·∫•y **0.005** ƒëi. S·ªë m·∫∑c ƒë·ªãnh l√† **0.001**  \n",
        "- **epochs**: 100 b·ªüi s·ªë l∆∞·ª£ng tham s·ªë t√≠nh to√°n n√†y l√† r·∫•t l·ªõn. üöÄ  "
      ],
      "metadata": {
        "id": "IPZykQp2nwWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(tokenizer.word_index) + 1 # v√¨ t·ª´ ƒëi·ªÉn b·∫Øt ƒë·∫ßu t·ª´ 1, s·ªë 0 ƒë∆∞·ª£c th√™m v√†o nh∆∞ padding"
      ],
      "metadata": {
        "id": "JS-L_59IaBRY",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model3 = Sequential([\n",
        "      Embedding(total_words, 16),\n",
        "      Bidirectional(LSTM(32, return_sequences=True)),\n",
        "      Bidirectional(LSTM(32)),\n",
        "      Dense(total_words, activation=\"softmax\")\n",
        "  ])\n",
        "  adam = Adam(learning_rate=0.01)\n",
        "  model3.compile(loss = 'sparse_categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "2SBGyebYQuGT",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "history3 = model3.fit(dataset, epochs = 100, verbose = 0)\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "Z4XR-DCiRE17",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model3.save(\"model3.h5\")"
      ],
      "metadata": {
        "id": "GJQQRopD7Qbg",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Th·ªùi gian hu·∫•n luy·ªán m√¥ h√¨nh: {timedelta(seconds=end_time - start_time)}\")"
      ],
      "metadata": {
        "id": "17RgwQEFRHft",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì hu·∫•n luy·ªán\n",
        "train_acc = history3.history[\"accuracy\"]\n",
        "train_loss = history3.history[\"loss\"]\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
        "axs = axs.flatten()\n",
        "axs[0].plot(train_acc)\n",
        "axs[0].set_title(\"Training Accuracy\")\n",
        "axs[1].plot(train_loss, color=\"orange\")\n",
        "axs[1].set_title(\"Training Loss\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xAdcyVxpRI8p",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha.\n",
        "\n",
        "![model3](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_8/model3.png?raw=true)"
      ],
      "metadata": {
        "id": "fl_fls36Lpyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "·ªû ƒë√¢y m·ªçi ng∆∞·ªùi th·∫•y gi·ªØa c√°c epoch ƒë√£ √≠t nhi·ªÖu h∆°n ha. C√≤n ph·∫ßn ƒë·ªôt ng·ªôt t·ª•t xu·ªëng ·ªü epoch kho·∫£ng 85 th√¨ do s·ª± ng·∫´u nhi√™n x√°o tr·ªôn d·ªØ l·ªôn th√¥i. ·ªû l·∫ßn ch·∫°y c·ªßa m·ªçi ng∆∞·ªùi c√≥ th·ªÉ kh√¥ng g·∫∑p ph·∫£i ƒë√¢u nha."
      ],
      "metadata": {
        "id": "DZu2beThLz4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ƒê√°nh gi√° m√¥ h√¨nh\n",
        "model3.evaluate(dataset)"
      ],
      "metadata": {
        "id": "ABtvvjgqRMzE",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫£i l·∫°i m√¥ h√¨nh\n",
        "model3 = load_model(\"model3.h5\")"
      ],
      "metadata": {
        "id": "IT-9aZxQHBSv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh d·ª± ƒëo√°n\n",
        "seed_text = \"sweet jeremy saw dublin\"\n",
        "num_words = 100\n",
        "predicted_text = seed_text\n",
        "\n",
        "# V√¨ k√≠ch th∆∞·ªõc ƒë·∫ßu v√†o ƒë√£ thay ƒë·ªïi theo k√≠ch th∆∞·ªõc c·ª≠a s·ªï\n",
        "# n√™n ta c≈©ng thay ƒë·ªïi ph·∫ßn c·∫Øt d·ªØ li·ªáu ƒë∆∞a v√†o t√≠\n",
        "for i in range(num_words):\n",
        "  # K√≠ch th∆∞·ªõc c·ª≠a s·ªï c·∫Øt ra ban ƒë·∫ßu l√† 6 nh∆∞ng ph·∫£i chia t·ª´ cu·ªëi cho nh√£n n√™n ƒë·∫ßu v√†o l√† 5\n",
        "  token_list = tokenizer.texts_to_sequences([predicted_text])[0]\n",
        "  # Ti·∫øn h√†nh ki·ªÉm tra lu√¥n n·∫øu k√≠ch th∆∞·ªõc kh√¥ng ƒë·ªß th√¨ padding v√†o ho·∫∑c d√†i qu√° th√¨ c√≥ th·ªÉ c·∫Øt ƒëi\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding=\"pre\")\n",
        "  token_list = np.array(token_list)\n",
        "  predicted_result = model3.predict(token_list)\n",
        "  predicted_index = np.argmax(predicted_result, axis=-1)\n",
        "  output_word = index_words.get(predicted_index[0], \"\") # N·∫øu index kh√¥ng c√≥ trong t·ª´ ƒëi·ªÉn, tr·∫£ v·ªÅ k√≠ t·ª± r·ªóng nh∆∞ padding\n",
        "\n",
        "  print(f\"Step {i}:\")\n",
        "  print(f\"T·ª´ d·ª± ƒëo√°n: {output_word} v·ªõi x√°c su·∫•t {predicted_result[0][predicted_index[0]]*100:2f}%\")\n",
        "  print(\"-\"*50)\n",
        "  predicted_text += \" \" + output_word\n"
      ],
      "metadata": {
        "id": "_eA1ZzADROy_",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"VƒÉn b·∫£n sinh ra: \\n{predicted_text}\")"
      ],
      "metadata": {
        "id": "PykF8WrdTJ05",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "K·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha.\n",
        "\n",
        "> VƒÉn b·∫£n sinh ra:\n",
        "'sweet jeremy saw dublin was my true love a tower near yon pure crystal fountain and hear in kilkenny and asked me chamber find in divil all us of all de de what all all was de in women more de'"
      ],
      "metadata": {
        "id": "EJ6XFLlxM7tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Character-Based Encoding  \n",
        "### T·ª•i m√¨nh s·∫Ω ti·∫øp c·∫≠n v·ªõi vi·ªác m√£ h√≥a ·ªü c·∫•p k√≠ t·ª± nha.  \n",
        "\n",
        "N·∫øu nh∆∞ ·ªü c√°c ch∆∞∆°ng tr∆∞·ªõc ch√∫ng ta th∆∞·ªùng hay s·ª≠ d·ª•ng m√£ h√≥a ·ªü c·∫•p t·ª´ th√¨ ·ªü ch∆∞∆°ng n√†y ch√∫ng ta c·∫ßn ph·∫£i xem x√©t l·∫°i. V·ªõi m·ªôt l∆∞·ª£ng vƒÉn b·∫£n kh·ªïng l·ªì nh∆∞ n√†y, k√≠ch th∆∞·ªõc b·ªô t·ª´ ƒëi·ªÉn t·ª´ c≈©ng s·∫Ω r·∫•t l√† l·ªõn. Khi ƒë·∫øn v·ªõi t√°c v·ª• t·∫°o sinh vƒÉn b·∫£n, ch·∫≥ng ph·∫£i ƒë·∫ßu c·ªßa m√¥ h√¨nh b·∫±ng v·ªõi k√≠ch th∆∞·ªõc b·ªô t·ª´ ƒëi·ªÉn v√† n√≥ th·∫≠t s·ª± l√† m·ªôt con s·ªë cho√°ng ng·ª£p.  \n",
        "\n",
        "Trong khi ƒë√≥ n·∫øu ta s·ª≠ d·ª•ng m√£ h√≥a ·ªü c·∫•p k√≠ t·ª± th√¨ k√≠ch th∆∞·ªõc b·ªô t·ª´ ƒëi·ªÉn s·∫Ω nh·ªè h∆°n r·∫•t nhi·ªÅu, ƒë·∫ßu ra m√† m√¥ h√¨nh c≈©ng √≠t h∆°n. Th·∫≠m ch√≠ th·∫•p h∆°n c·∫£ trƒÉm l·∫ßn. ‚ú®  \n",
        "\n",
        "**VD**: Ch√∫ng ta c√≥ m·ªôt b·ªô d·ªØ li·ªáu vƒÉn b·∫£n:  \n",
        "- Khi m√£ h√≥a ·ªü c·∫•p t·ª´, b·ªô t·ª´ ƒëi·ªÉn c·ªßa ch√∫ng ta c√≥ k√≠ch th∆∞·ªõc l√† **2700** t∆∞∆°ng ·ª©ng v·ªõi 2700 t·ª´ ri√™ng bi·ªát.  \n",
        "- Tuy nhi√™n khi m√£ h√≥a ·ªü c·∫•p k√≠ t·ª± th√¨ k√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ch·ªâ c√≤n **48**, nh·ªè h∆°n r·∫•t l√† nhi·ªÅu, m√¥ h√¨nh c≈©ng ch·ªâ c·∫ßn d·ª± ƒëo√°n ƒë·∫ßu ra l√† **48 nh√£n** thay v√¨ **2700** nh∆∞ tr∆∞·ªõc.  \n",
        "\n",
        "Qua c√°ch m√£ h√≥a d·ªØ li·ªáu tr√™n th√¨ m√¥ h√¨nh c·ªßa ch√∫ng ta s·∫Ω ƒë∆°n gi·∫£n h∆°n r·∫•t nhi·ªÅu, ngo√†i ra c≈©ng c√≥ th·ªÉ ch·ª©a c√°c k√≠ t·ª± ƒë·∫∑c bi·ªát. üöÄ  \n",
        "\n",
        "***L∆∞u √Ω: ·ªû ƒë√¢y m√¨nh s·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu irish-lyrics-eof.txt nha t·∫°i b·ªô d·ªØ li·ªáu \"The Complete Works of William Shakespeare\" m√† t√°c gi·∫£ s·ª≠ d·ª•ng qu√° l·ªõn, ∆∞·ªõc t√≠nh g·∫•p g·∫ßn 10 l·∫ßn b·ªô irish lyrics. M√¨nh c√≥ th·ª≠ train nh∆∞ng qua 10 ti·∫øng v·∫´n ch∆∞a xong ƒë∆∞·ª£c, m·ªõi ƒë·∫øn epoch 7. D·ªØ li·ªáu m√† ch√∫ng ta ti·ªÅn x·ª≠ l√Ω v√† t·∫°o ra c≈©ng v∆∞·ª£t qua ng∆∞·ª°ng 12GB tr√™n ram.***"
      ],
      "metadata": {
        "id": "UkZ0nLZ8diuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jamzhu/irishlyricseof\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "CnwJB1vtLunZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Li·ªát k√™ danh s√°ch file\n",
        "for f in os.listdir(path):\n",
        "  print(f)"
      ],
      "metadata": {
        "id": "GdZ1qbPmMRSH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load d·ªØ li·ªáu v√†o\n",
        "# data = open(\"/kaggle/input/irishlyricseof/irish-lyrics-eof.txt\", \"r\").read()\n",
        "data = open(os.path.join(path, \"irish-lyrics-eof.txt\"), \"r\").read()\n",
        "# Ki·ªÉm tra d·ªØ li·ªáu\n",
        "print(data[:120])"
      ],
      "metadata": {
        "id": "REwsNOH6MIac",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:00.188866Z",
          "iopub.execute_input": "2024-12-28T15:03:00.189163Z",
          "iopub.status.idle": "2024-12-28T15:03:00.205096Z",
          "shell.execute_reply.started": "2024-12-28T15:03:00.189119Z",
          "shell.execute_reply": "2024-12-28T15:03:00.204432Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:00.206235Z",
          "iopub.execute_input": "2024-12-28T15:03:00.206533Z",
          "iopub.status.idle": "2024-12-28T15:03:00.211727Z",
          "shell.execute_reply.started": "2024-12-28T15:03:00.206505Z",
          "shell.execute_reply": "2024-12-28T15:03:00.210924Z"
        },
        "id": "OvK7zg55GLro"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh chia c√¢u d·ª±a tr√™n c·ª≠a s·ªï tr∆∞·ª£t\n",
        "window_size = 65\n",
        "corpus = data.lower()\n",
        "\n",
        "# L·∫•y danh s√°ch k√≠ t·ª±\n",
        "characters = list(corpus)\n",
        "# print(characters)\n",
        "\n",
        "# Chia c√¢u (chu·ªói) d·ª±a tr√™n c·ª≠a s·ªï tr∆∞·ª£t\n",
        "range_size = len(characters) - window_size + 1\n",
        "input_sentences = []\n",
        "for i in range(range_size):\n",
        "  input_sentences.append(\"\".join(characters[i:i+window_size]))\n",
        "\n",
        "# Ki·ªÉm tra 5 c√¢u (chu·ªói) ƒë·∫ßu ti√™n:\n",
        "for i in range(5):\n",
        "  print(repr(input_sentences[i]))"
      ],
      "metadata": {
        "id": "2iMBBlmNMfQ1",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:00.213153Z",
          "iopub.execute_input": "2024-12-28T15:03:00.213404Z",
          "iopub.status.idle": "2024-12-28T15:03:00.300592Z",
          "shell.execute_reply.started": "2024-12-28T15:03:00.213378Z",
          "shell.execute_reply": "2024-12-28T15:03:00.300000Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Ti·∫øn h√†nh t·∫°o b·ªô m√£ h√≥a c·∫•p k√≠ t·ª±\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(input_sentences)\n"
      ],
      "metadata": {
        "id": "BunmodZQNtEY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:00.301631Z",
          "iopub.execute_input": "2024-12-28T15:03:00.301897Z",
          "iopub.status.idle": "2024-12-28T15:03:01.292485Z",
          "shell.execute_reply.started": "2024-12-28T15:03:00.301870Z",
          "shell.execute_reply": "2024-12-28T15:03:01.291818Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"T·ªïng s·ªë l∆∞·ª£ng k√≠ t·ª±: {len(tokenizer.word_index)}\")\n",
        "print(f\"B·ªô t·ª´ ƒëi·ªÉn t·ª´ v·ª±ng: {tokenizer.word_index}\")"
      ],
      "metadata": {
        "id": "3PB_cfGIUNj7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:01.293174Z",
          "iopub.execute_input": "2024-12-28T15:03:01.293378Z",
          "iopub.status.idle": "2024-12-28T15:03:01.297797Z",
          "shell.execute_reply.started": "2024-12-28T15:03:01.293360Z",
          "shell.execute_reply": "2024-12-28T15:03:01.297008Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o b·ªô t·ª´ ƒëi·ªÉn chuy·ªÉn ƒë·ªïi\n",
        "index_words = {}\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  index_words[index] = word"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:01.299571Z",
          "iopub.execute_input": "2024-12-28T15:03:01.299784Z",
          "iopub.status.idle": "2024-12-28T15:03:01.313485Z",
          "shell.execute_reply.started": "2024-12-28T15:03:01.299741Z",
          "shell.execute_reply": "2024-12-28T15:03:01.312886Z"
        },
        "id": "cpgz1jU8GLro"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "·ªû ƒë√¢y t·ª•i m√¨nh s·∫Ω c√≥ 2 c√°ch chia d·ªØ li·ªáu, t·∫°o dataset nha.\n",
        "\n",
        "**C√°ch 1:** Ch·ªâ d√πng c·ª≠a s·ªï tr∆∞·ª£t t·∫°o d·ªØ li·ªáu.\n",
        "\n",
        "**C√°ch 2:** L√†m c√°ch 1 v√† l√†m th√™m c·∫£ b∆∞·ªõc t·∫°o chu·ªói con.\n",
        "\n",
        "> **T·∫°i sao m√¨nh l·∫°i ƒë·ªÉ 2 c√°ch tr√™n?**\n",
        "\n",
        "**C√¢u tr·∫£ l·ªùi l√†:** V√¨ b·ªô d·ªØ li·ªáu qu√° l·ªõn, ·ªü c√°ch 2 m√¨nh ƒë√£ d√πng 10 ti·∫øng ƒë·ªÉ hu·∫•n luy·ªán nh∆∞ng v·∫´n ch·ªâ ƒë·∫øn ƒë∆∞·ª£c epoch 8. V·ªÅ c∆° b·∫£n v·∫´n hu·∫•n luy·ªán ƒë∆∞·ª£c nh∆∞ng l∆∞·ª£ng th·ªùi gian qu√° l√¢u n√™n m√¨nh t·∫°m th·ªùi v·∫´n ch∆∞a th·ªÉ xu·∫•t ra k·∫øt qu·∫£ c√°ch 2 ƒë∆∞·ª£c n√™n m√¨nh t·∫°m ti·∫øn h√†nh hu·∫•n luy·ªán tr√™n d·ªØ li·ªáu ·ªü c√°ch 1 nha."
      ],
      "metadata": {
        "id": "HWMH-WSeYNXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = 0\n",
        "\n",
        "input_sequences = []\n",
        "\n",
        "for sentence in input_sentences:\n",
        "    token_list = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    if len(token_list) > max_sequence_len:\n",
        "      max_sequence_len = len(token_list)\n",
        "    input_sequences.append(token_list)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:01.314430Z",
          "iopub.execute_input": "2024-12-28T15:03:01.314664Z",
          "iopub.status.idle": "2024-12-28T15:03:02.059196Z",
          "shell.execute_reply.started": "2024-12-28T15:03:01.314645Z",
          "shell.execute_reply": "2024-12-28T15:03:02.058503Z"
        },
        "id": "gk70avwkGLrp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ƒê·ªô d√†i t·ªëi ƒëa c·ªßa chu·ªói: \", max_sequence_len)"
      ],
      "metadata": {
        "trusted": true,
        "id": "y7VK7hjvGLrp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding=\"pre\"))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:02.059953Z",
          "iopub.execute_input": "2024-12-28T15:03:02.060289Z",
          "iopub.status.idle": "2024-12-28T15:03:02.350901Z",
          "shell.execute_reply.started": "2024-12-28T15:03:02.060256Z",
          "shell.execute_reply": "2024-12-28T15:03:02.350225Z"
        },
        "id": "E73qP6slGLrp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "xs = input_sequences[:,:-1]\n",
        "labels = input_sequences[:,-1]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:02.351708Z",
          "iopub.execute_input": "2024-12-28T15:03:02.351940Z",
          "iopub.status.idle": "2024-12-28T15:03:02.355643Z",
          "shell.execute_reply.started": "2024-12-28T15:03:02.351919Z",
          "shell.execute_reply": "2024-12-28T15:03:02.354809Z"
        },
        "id": "K9ZbsqprGLrp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((xs, labels))\n",
        "\n",
        "# T·ªëi ∆∞u Dataset v·ªõi shuffle, batch v√† prefetch\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "dataset = (\n",
        "    dataset\n",
        "    .cache(\"train_cache.tfdata\")    # Thay v√¨ l∆∞u d·ªØ li·ªáu v√†o ram th√¨ l∆∞u h·∫≥n v√†o disk\n",
        "    .shuffle(buffer_size=1000)      # Tr·ªôn d·ªØ li·ªáu\n",
        "    .batch(32)                      # Chia batch (batch_size=32)\n",
        "    .prefetch(buffer_size=AUTOTUNE) # T·∫£i tr∆∞·ªõc d·ªØ li·ªáu\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:02.356665Z",
          "iopub.execute_input": "2024-12-28T15:03:02.356899Z",
          "iopub.status.idle": "2024-12-28T15:03:02.396744Z",
          "shell.execute_reply.started": "2024-12-28T15:03:02.356880Z",
          "shell.execute_reply": "2024-12-28T15:03:02.396169Z"
        },
        "id": "tZBLni0xGLrp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "D∆∞·ªõi n√†y l√† ƒëo·∫°n code ƒë·ªÉ t·∫°o d·ªØ li·ªáu c√°ch 2 nha. V√¨ b·ªô d·ªØ li·ªáu qu√° l·ªõn n√™n ch√∫ng ta s·∫Ω ti·∫øn h√†nh th√™m d·ªØ li·ªáu t·ª´ t·ª´ v√†o file pickle."
      ],
      "metadata": {
        "id": "HpckbXQCGLrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # T·∫°o file t·∫°m ƒë·ªÉ l∆∞u d·ªØ li·ªáu\n",
        "# temp_file = \"sub_sequences_temp.pkl\"\n",
        "# max_sequence_len = 0\n",
        "\n",
        "# # input_sequences = []\n",
        "\n",
        "# with open(temp_file, \"wb\") as f:\n",
        "#   for sentence in input_sentences:\n",
        "#     token_list = tokenizer.texts_to_sequences([sentence])[0]\n",
        "#     if len(token_list) > max_sequence_len:\n",
        "#         max_sequence_len = len(token_list)\n",
        "#     for i in range(1, len(token_list)):\n",
        "#         n_gram_sequence = token_list[:i+1]\n",
        "#         pickle.dump(n_gram_sequence, f)\n",
        "\n",
        "# print(f\"ƒê·ªô d√†i chu·ªói d√†i nh·∫•t: {max_sequence_len}\")"
      ],
      "metadata": {
        "id": "vKcsonfbUPcw",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:02.397456Z",
          "iopub.execute_input": "2024-12-28T15:03:02.397641Z",
          "iopub.status.idle": "2024-12-28T15:03:02.400810Z",
          "shell.execute_reply.started": "2024-12-28T15:03:02.397621Z",
          "shell.execute_reply": "2024-12-28T15:03:02.400033Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "temp_file = \"/kaggle/working/sub_sequences_temp.pkl\"\n",
        "def read_sequences_in_batches(file_path, batch_size):\n",
        "    \"\"\"\n",
        "    H√†m generator ƒë·ªçc d·ªØ li·ªáu t·ª´ file Pickle theo t·ª´ng batch.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        batch = []\n",
        "        while True:\n",
        "            try:\n",
        "                # ƒê·ªçc t·ª´ng chu·ªói\n",
        "                token_list = pickle.load(f)\n",
        "                batch.append(token_list)\n",
        "                # N·∫øu ƒë·ªß batch size, yield batch v√† kh·ªüi t·∫°o l·∫°i\n",
        "                if len(batch) == batch_size:\n",
        "                    yield batch\n",
        "                    batch = []\n",
        "            except EOFError:\n",
        "                # Tr·∫£ v·ªÅ batch cu·ªëi c√πng n·∫øu c√≤n d·ªØ li·ªáu\n",
        "                if batch:\n",
        "                    yield batch\n",
        "                break"
      ],
      "metadata": {
        "id": "FxHjXDFme2Gw",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:02.401583Z",
          "iopub.execute_input": "2024-12-28T15:03:02.401866Z",
          "iopub.status.idle": "2024-12-28T15:03:02.418777Z",
          "shell.execute_reply.started": "2024-12-28T15:03:02.401836Z",
          "shell.execute_reply": "2024-12-28T15:03:02.418204Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def process_batch(batch, max_seq_length):\n",
        "    \"\"\"\n",
        "    Pad c√°c chu·ªói v√† t√°ch X (input), labels (output).\n",
        "    \"\"\"\n",
        "    # Pad c√°c chu·ªói ƒë·∫øn chi·ªÅu d√†i t·ªëi ƒëa\n",
        "    padded_batch = pad_sequences(batch, maxlen=max_seq_length, padding='pre')\n",
        "\n",
        "    # T√°ch X v√† labels\n",
        "    X = padded_batch[:, :-1]  # T·∫•t c·∫£ tr·ª´ ph·∫ßn t·ª≠ cu·ªëi\n",
        "    labels = padded_batch[:, -1]  # Ph·∫ßn t·ª≠ cu·ªëi c√πng l√†m nh√£n\n",
        "    return X, labels"
      ],
      "metadata": {
        "id": "bkcQWUNPe9MR",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:02.419462Z",
          "iopub.execute_input": "2024-12-28T15:03:02.419702Z",
          "iopub.status.idle": "2024-12-28T15:03:02.441348Z",
          "shell.execute_reply.started": "2024-12-28T15:03:02.419682Z",
          "shell.execute_reply": "2024-12-28T15:03:02.440588Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(file_path, batch_size, max_seq_length):\n",
        "    for batch in read_sequences_in_batches(file_path, batch_size):\n",
        "        X, labels = process_batch(batch, max_seq_length)\n",
        "        yield X, labels"
      ],
      "metadata": {
        "id": "1NzkFZtefsmT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:02.443584Z",
          "iopub.execute_input": "2024-12-28T15:03:02.443836Z",
          "iopub.status.idle": "2024-12-28T15:03:02.458027Z",
          "shell.execute_reply.started": "2024-12-28T15:03:02.443797Z",
          "shell.execute_reply": "2024-12-28T15:03:02.457494Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "N·∫øu m·ªçi ng∆∞·ªùi mu·ªën ch·∫°y th·ª≠ ph·∫ßn dataset c√≥ chia theo chu·ªói con th√¨ m·ªü comment v√† ch·∫°y ti·∫øp ƒëo·∫°n code d∆∞·ªõi ƒë√¢y nha. Ch√∫ng s·∫Ω t·∫°o lu·ªìng ƒë·ªÉ ti·∫øn h√†nh hu·∫•n luy·ªán d·ªØ li·ªáu t·ª´ file pickle.\n",
        "\n",
        "L∆∞u √Ω: c√°ch n√†y kh√¥ng ph·∫£i l√† l·∫•y to√†n b·ªô d·ªØ li·ªáu t·ª´ file pickle nha n√™n kh√¥ng c·∫ßn lo s·∫Ω b·ªã tr√†n ram."
      ],
      "metadata": {
        "id": "GjewegUYGLrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# temp_file = \"/kaggle/working/sub_sequences_temp.pkl\"\n",
        "# batch_size = 16\n",
        "# dataset = tf.data.Dataset.from_generator(\n",
        "#     lambda: data_generator(temp_file, batch_size, max_sequence_len),\n",
        "#     output_signature=(\n",
        "#         tf.TensorSpec(shape=(None, max_sequence_len - 1), dtype=tf.int32),  # X\n",
        "#         tf.TensorSpec(shape=(None,), dtype=tf.int32)  # labels\n",
        "#     )\n",
        "# )\n",
        "\n",
        "# # Prefetch ƒë·ªÉ tƒÉng hi·ªáu su·∫•t\n",
        "# dataset = dataset.cache(\"train_cache.tfdata\").prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:02.459381Z",
          "iopub.execute_input": "2024-12-28T15:03:02.459642Z",
          "iopub.status.idle": "2024-12-28T15:03:02.474057Z",
          "shell.execute_reply.started": "2024-12-28T15:03:02.459614Z",
          "shell.execute_reply": "2024-12-28T15:03:02.473318Z"
        },
        "id": "4LCLrgOzGLrq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ki·ªÉm tra s·ªë l∆∞·ª£ng k√≠ t·ª± t·ªëi ƒëa\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(f\"S·ªë l∆∞·ª£ng k√≠ t·ª±: {total_words}\")"
      ],
      "metadata": {
        "id": "6Z6XxkOd7NCM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:02.474853Z",
          "iopub.execute_input": "2024-12-28T15:03:02.475081Z",
          "iopub.status.idle": "2024-12-28T15:03:02.493095Z",
          "shell.execute_reply.started": "2024-12-28T15:03:02.475053Z",
          "shell.execute_reply": "2024-12-28T15:03:02.492487Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "U·∫ßy v·∫≠y l√† s·ªë l∆∞·ª£ng nh√£n ƒë·∫ßu ra m√† m√¥ h√¨nh ph·∫£i d·ª± ƒëo√°n ƒë√£ th·∫•p h∆°n r·∫•t nhi·ªÅu r·ªìi, ch·ªâ 66 k√≠ t·ª±. B√¢y gi·ªù t·ª•i m√¨nh ti·∫øn h√†nh ƒë·ªãnh nghƒ©a v√† hu·∫•n luy·ªán m√¥ h√¨nh th·ª≠ nha."
      ],
      "metadata": {
        "id": "GgB-oFNmiFwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ƒê·ªãnh nghƒ©a m√¥ h√¨nh\n",
        "with strategy.scope():\n",
        "  model4 = Sequential([\n",
        "      Embedding(total_words, 16),\n",
        "      Bidirectional(LSTM(32, return_sequences=True)),\n",
        "      Bidirectional(LSTM(32)),\n",
        "      Dense(total_words, activation=\"softmax\")\n",
        "  ])\n",
        "  adam = Adam(learning_rate=0.01)\n",
        "  model4.compile(loss = 'sparse_categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "yQfaeQaz72L-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:08:56.099743Z",
          "iopub.execute_input": "2024-12-28T15:08:56.100020Z",
          "iopub.status.idle": "2024-12-28T15:08:56.146793Z",
          "shell.execute_reply.started": "2024-12-28T15:08:56.099998Z",
          "shell.execute_reply": "2024-12-28T15:08:56.146205Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()"
      ],
      "metadata": {
        "id": "0egK2V0mA5ts",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:03:02.588987Z",
          "iopub.execute_input": "2024-12-28T15:03:02.589301Z",
          "iopub.status.idle": "2024-12-28T15:03:02.604303Z",
          "shell.execute_reply.started": "2024-12-28T15:03:02.589255Z",
          "shell.execute_reply": "2024-12-28T15:03:02.603647Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "history4 = model4.fit(dataset, epochs = 100, verbose = 1)\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "I7MPVbZS8AMA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:08:58.603152Z",
          "iopub.execute_input": "2024-12-28T15:08:58.603477Z",
          "iopub.status.idle": "2024-12-28T16:22:32.507027Z",
          "shell.execute_reply.started": "2024-12-28T15:08:58.603449Z",
          "shell.execute_reply": "2024-12-28T16:22:32.506200Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model4.save(\"model4.h5\")"
      ],
      "metadata": {
        "id": "VkqHVuCl7Wgt",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T16:22:32.508431Z",
          "iopub.execute_input": "2024-12-28T16:22:32.508651Z",
          "iopub.status.idle": "2024-12-28T16:22:32.581902Z",
          "shell.execute_reply.started": "2024-12-28T16:22:32.508632Z",
          "shell.execute_reply": "2024-12-28T16:22:32.581216Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Th·ªùi gian hu·∫•n luy·ªán m√¥ h√¨nh: {timedelta(seconds=end_time - start_time)}\")"
      ],
      "metadata": {
        "id": "al72VLFa8SME",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T16:22:32.583536Z",
          "iopub.execute_input": "2024-12-28T16:22:32.583822Z",
          "iopub.status.idle": "2024-12-28T16:22:32.588565Z",
          "shell.execute_reply.started": "2024-12-28T16:22:32.583798Z",
          "shell.execute_reply": "2024-12-28T16:22:32.587461Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì qu√° tr√¨nh hu·∫•n luy·ªán\n",
        "train_acc = history4.history[\"accuracy\"]\n",
        "train_loss = history4.history[\"loss\"]\n",
        "\n",
        "fig,axs = plt.subplots(1, 2, figsize = (12, 4))\n",
        "axs = axs.flatten()\n",
        "axs[0].plot(train_acc)\n",
        "axs[0].set_title(\"Training Accuracy\")\n",
        "axs[1].plot(train_loss, color=\"orange\")\n",
        "axs[1].set_title(\"Training Loss\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S5xK6oNW8UUS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T16:24:42.941357Z",
          "iopub.execute_input": "2024-12-28T16:24:42.941665Z",
          "iopub.status.idle": "2024-12-28T16:24:43.506296Z",
          "shell.execute_reply.started": "2024-12-28T16:24:42.941641Z",
          "shell.execute_reply": "2024-12-28T16:24:43.505441Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha.\n",
        "\n",
        "![model4](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_8/model4.jpg?raw=true)"
      ],
      "metadata": {
        "id": "u-OsiqcWTRK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4.evaluate(dataset)"
      ],
      "metadata": {
        "id": "DSSahWnHA4yt",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T16:25:19.693935Z",
          "iopub.execute_input": "2024-12-28T16:25:19.694278Z",
          "iopub.status.idle": "2024-12-28T16:25:37.188042Z",
          "shell.execute_reply.started": "2024-12-28T16:25:19.694249Z",
          "shell.execute_reply": "2024-12-28T16:25:37.187394Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# C·∫≠p nh·∫≠t tr·ªçng s·ªë t·ª´ m√¥ h√¨nh ƒë√£ l∆∞u\n",
        "model4 = load_model('model4.h5')"
      ],
      "metadata": {
        "id": "8Y6lTIs2AQ2U",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T16:26:00.928521Z",
          "iopub.execute_input": "2024-12-28T16:26:00.928864Z",
          "iopub.status.idle": "2024-12-28T16:26:01.198937Z",
          "shell.execute_reply.started": "2024-12-28T16:26:00.928836Z",
          "shell.execute_reply": "2024-12-28T16:26:01.198328Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh d·ª± ƒëo√°n\n",
        "seed_text = \"\"\"YGRITTE:\n",
        " You know nothing, Jon Snow.\n",
        " Good night, we‚Äôll prove those body‚Äôs servants to\n",
        " \"\"\"\n",
        "\n",
        "num_words = 1000\n",
        "predicted_text = seed_text\n",
        "\n",
        "# V√¨ k√≠ch th∆∞·ªõc ƒë·∫ßu v√†o ƒë√£ thay ƒë·ªïi theo k√≠ch th∆∞·ªõc c·ª≠a s·ªï\n",
        "# n√™n ta c≈©ng thay ƒë·ªïi ph·∫ßn c·∫Øt d·ªØ li·ªáu ƒë∆∞a v√†o t√≠\n",
        "for i in range(num_words):\n",
        "  # K√≠ch th∆∞·ªõc c·ª≠a s·ªï c·∫Øt ra ban ƒë·∫ßu l√† 6 nh∆∞ng ph·∫£i chia t·ª´ cu·ªëi cho nh√£n n√™n ƒë·∫ßu v√†o l√† 5\n",
        "  token_list = tokenizer.texts_to_sequences([predicted_text])[0]\n",
        "  # Ti·∫øn h√†nh ki·ªÉm tra lu√¥n n·∫øu k√≠ch th∆∞·ªõc kh√¥ng ƒë·ªß th√¨ padding v√†o ho·∫∑c d√†i qu√° th√¨ c√≥ th·ªÉ c·∫Øt ƒëi\n",
        "  token_list = pad_sequences([token_list], maxlen=window_size-1, padding=\"pre\")\n",
        "  token_list = np.array(token_list)\n",
        "  predicted_result = model4.predict(token_list)\n",
        "  predicted_index = np.argmax(predicted_result, axis=-1)\n",
        "  output_char = index_words.get(predicted_index[0], \"\")\n",
        "\n",
        "  print(f\"Step {i}:\")\n",
        "  print(f\"T·ª´ d·ª± ƒëo√°n: {output_char} v·ªõi x√°c su·∫•t {predicted_result[0][predicted_index[0]]*100:2f}%\")\n",
        "  print(\"-\"*50)\n",
        "  predicted_text += output_char\n"
      ],
      "metadata": {
        "id": "OcJsdx5WE1JU",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T16:26:04.001432Z",
          "iopub.execute_input": "2024-12-28T16:26:04.001805Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"VƒÉn b·∫£n sinh ra:\")\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "id": "h7UaPsBUc5vo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T15:08:53.089168Z",
          "iopub.status.idle": "2024-12-28T15:08:53.089552Z",
          "shell.execute_reply": "2024-12-28T15:08:53.089388Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "K·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha.\n",
        "\n",
        "> YGRITTE:\n",
        " You know nothing, Jon Snow.\n",
        " Good night, we‚Äôll prove those body‚Äôs servants to\n",
        " the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love the love t"
      ],
      "metadata": {
        "id": "Sce6sechNLr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y c≈©ng l√† ƒëi·ªÉm m√† m√¨nh th·∫•y kh√≥ hi·ªÉu nh·∫•t. Theo nh∆∞ trong s√°ch th√¨ t√°c gi·∫£ n√≥i ph∆∞∆°ng ph√°p hu·∫•n luy·ªán ·ªü c·∫•p k√≠ t·ª± n√†y s·∫Ω hi·ªáu qu·∫£ v√† ƒë√°ng kinh ng·∫°c h∆°n r·∫•t nhi·ªÅu.\n",
        "\n",
        "Th√¥ng qua vi·ªác h·ªçc d·ª±a tr√™n c·∫•p k√≠ t·ª±, m√¥ h√¨nh c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c c·∫£ c√°c k√≠ t·ª± ƒë·∫∑c bi·ªát, k√≠ hi·ªáu xu·ªëng h√†ng.\n",
        "\n",
        "Tuy nhi√™n ·ªü k·∫øt qu·∫£ t·∫°o ra, ch√∫ng ta l·∫°i th·∫•y kh√° t·ªá. M√¨nh nghƒ© m·ªôt ph·∫ßn l√Ω do nh∆∞ sau:\n",
        "\n",
        "1. Ch√∫ng ƒë·∫øn t·ª´ vi·ªác chia d·ªØ li·ªáu c·ªßa m√¨nh v√¨ ch√∫ng ta ch·ªâ l√†m theo c√°ch 1 n√™n l∆∞·ª£ng d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán ƒë√£ √≠t h∆°n nhi·ªÅu d·∫´n ƒë·∫øn m√¥ h√¨nh cho ra ƒë·ªô hi·ªáu qu·∫£ k√©m h∆°n h·∫≥n.\n",
        "\n",
        "2. T·ª•i m√¨nh s·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu Irish song thay v√¨ b·ªô d·ªØ li·ªáu c·ªßa Shakespear. Khi m√¨nh ki·ªÉm tra th√¨ b·ªô d·ªØ li·ªáu Shakespear n·∫∑ng h∆°n g·∫ßn 10 l·∫ßn."
      ],
      "metadata": {
        "id": "IzOkR8wqNebE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T·ªïng k·∫øt ch∆∞∆°ng 8 ( ‚Ä¢ÃÄ œâ ‚Ä¢ÃÅ )‚úß\n",
        "\n",
        "T·ª•i m√¨nh ƒë√£ l∆∞·ª£n m·ªôt v√≤ng qua c√°c vƒÉn b·∫£n v√† h·ªçc c√°ch ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu hu·∫•n luy·ªán v√† t·∫°o/sinh vƒÉn b·∫£n ·ªü c·∫•p ƒë·ªô th√¥ s∆°.\n",
        "\n",
        "- Ti·ªÅn x·ª≠ l√Ω, chia d·ªØ li·ªáu hu·∫•n luy·ªán b·∫±ng c·ª≠a s·ªï tr∆∞·ª£t.\n",
        "- C√°c c√°ch ti·∫øp c·∫≠n m√£ h√≥a d·ªØ li·ªáu hu·∫•n luy·ªán ·ªü c·∫•p t·ª´ v√† c·∫•p k√≠ t·ª±."
      ],
      "metadata": {
        "id": "c4PirJTBRjYD"
      }
    }
  ]
}