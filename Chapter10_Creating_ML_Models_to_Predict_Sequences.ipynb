{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/Chapter10_Creating_ML_Models_to_Predict_Sequences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KWus4RuJ2GZ"
      },
      "source": [
        "# Chapter 10: Creating ML Models to Predict Sequences  \n",
        "## T·∫°o ra c√°c m√¥ h√¨nh h·ªçc m√°y ƒë·ªÉ d·ª± ƒëo√°n chu·ªói\n",
        "\n",
        "Hi, ch√†o m·ªçi ng∆∞·ªùi, t·ª•i m√¨nh l·∫°i g·∫∑p nhau r·ªìi. üòä  \n",
        "\n",
        "·ªû ch∆∞∆°ng tr∆∞·ªõc, ch√∫ng ta ƒë√£ c√πng t√¨m hi·ªÉu v·ªÅ d·ªØ li·ªáu chu·ªói th·ªùi gian c≈©ng nh∆∞ c√°c ph∆∞∆°ng ph√°p c∆° b·∫£n ƒë·ªÉ d·ª± ƒëo√°n ch√∫ng. H√¥m nay, t·ª•i m√¨nh s·∫Ω c√πng t√¨m hi·ªÉu s√¢u h∆°n v·ªÅ c√°c ph∆∞∆°ng ph√°p h·ªçc m√°y ƒë·ªÉ d·ª± ƒëo√°n nha. üíª  \n",
        "\n",
        "Tuy nhi√™n, tr∆∞·ªõc khi ƒëi v√†o c√°c m√¥ h√¨nh d·ª± ƒëo√°n, t·ª•i m√¨nh s·∫Ω ph·∫£i t√¨m hi·ªÉu v·ªÅ c·∫•u tr√∫c d·ªØ li·ªáu c·∫ßn chu·∫©n b·ªã ƒë·ªÉ ƒë∆∞a v√†o m√¥ h√¨nh nha.  \n",
        "V·ªÅ c∆° b·∫£n th√¨ kh√¢u chu·∫©n b·ªã n√†y c≈©ng kh√¥ng kh√°c g√¨ m·∫•y ·ªü ch∆∞∆°ng tr∆∞·ªõc, nh∆∞ng s·∫Ω b√†i b·∫£n h∆°n khi m√† ph·∫ßn d·ªØ li·ªáu n√†y s·∫Ω c√≥ t√™n g·ªçi l√† **\"windowed dataset\"**. üß©  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnqN_V5xLXZW"
      },
      "source": [
        "ƒê√¢y l√† bi·ªÉu ƒë·ªì d·ªØ li·ªáu c·ªßa t·ª•i m√¨nh ·ªü ch∆∞∆°ng tr∆∞·ªõc nha."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![real_data](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_10/real_data.png?raw=true)"
      ],
      "metadata": {
        "id": "5MZMJr86LLiG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OdYHQSZNpbD"
      },
      "source": [
        "**ƒê·ªãnh nghƒ©a:** \"windowed dataset\" l√† m·ªôt t·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c t·∫°o ra b·∫±ng c√°ch chia d·ªØ li·ªáu th·ªùi gian th√†nh c√°c **\"c·ª≠a s·ªï d·ªØ li·ªáu\"** v·ªõi m·ªói c·ª≠a s·ªï ch·ª©a *n* gi√° tr·ªã li√™n ti·∫øp t·∫°i c√°c b∆∞·ªõc d·ªØ li·ªáu th·ªùi gian, ƒë·∫°i di·ªán cho **ƒë·∫∑c tr∆∞ng** ƒë∆∞a v√†o m√¥ h√¨nh, v√† gi√° tr·ªã ti·∫øp theo s·∫Ω l√† **nh√£n** c·ªßa c·ª≠a s·ªï ƒë√≥. üìä\n",
        "\n",
        "N·∫øu b·∫°n mu·ªën d·ª± ƒëo√°n gi√° tr·ªã t·∫°i th·ªùi ƒëi·ªÉm **(t)** th√¨ c·∫ßn ph·∫£i s·ª≠ d·ª•ng **n** gi√° tr·ªã tr∆∞·ªõc ƒë√≥ l√†m d·ªØ li·ªáu ƒë·∫ßu v√†o. Trong ƒë√≥, **n** ch√≠nh l√† k√≠ch th∆∞·ªõc c·ªßa **\"c·ª≠a s·ªï d·ªØ li·ªáu\"**. üïí\n",
        "\n",
        "**VD:** ƒê·ªãnh nghƒ©a **n = 30**. ƒê·ªÉ d·ª± ƒëo√°n gi√° tr·ªã t·∫°i th·ªùi ƒëi·ªÉm **t = 1200**, ta c·∫ßn s·ª≠ d·ª•ng c√°c gi√° tr·ªã t·ª´ th·ªùi ƒëi·ªÉm **t = 1170 ƒë·∫øn 1199**. üîç"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![windowed_data](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_10/windowed_data.png?raw=true)"
      ],
      "metadata": {
        "id": "2yWG-hB5LPoG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozoEaPuHP4hf"
      },
      "source": [
        "V·∫≠y c√°c gi√° tr·ªã t·∫°i th·ªùi ƒëi·ªÉm **t = 1970 ƒë·∫øn 1999** s·∫Ω ƒë∆∞·ª£c coi l√† ph·∫ßn **ƒë·∫∑c tr∆∞ng**, c√≤n gi√° tr·ªã c·∫ßn d·ª± ƒëo√°n t·∫°i th·ªùi ƒëi·ªÉm **t = 2000** ƒë∆∞·ª£c g·ªçi l√† **nh√£n**. üéØ\n",
        "\n",
        "T∆∞∆°ng t·ª± nh∆∞ v·∫≠y, th√¥ng qua vi·ªác **tr∆∞·ª£t d√†i c·ª≠a s·ªï li√™n t·ª•c** tr√™n b·ªô d·ªØ li·ªáu th·ªùi gian, ta s·∫Ω thu ƒë∆∞·ª£c b·ªô d·ªØ li·ªáu mong mu·ªën ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh, c√≥ t√™n g·ªçi l√† **\"windowed dataset\"**. üñ•Ô∏è\n",
        "\n",
        "*P/s: M√¨nh nghƒ© m·ªçi ng∆∞·ªùi n√™n d√πng t·ª´ **windowed dataset** h∆°n nha. N√≥ l√† m·ªôt thu·∫≠t ng·ªØ chuy√™n ng√†nh √°. Ch√∫ng ta c√≥ th·ªÉ gi·∫£i th√≠ch ƒë∆°n gi·∫£n l√† **window dataset** l√† b·ªô d·ªØ li·ªáu d·∫°ng chu·ªói ƒë∆∞·ª£c t·∫°o ra b·∫±ng ph∆∞∆°ng ph√°p c·ª≠a s·ªï tr∆∞·ª£t.* üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hz2PABnRK-d"
      },
      "source": [
        "# Creating a Windowed Dataset üèóÔ∏è\n",
        "\n",
        "B√¢y gi·ªù, t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh th·ª≠ t·∫°o ra **\"Windowed dataset\"** nha. üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7lgsg88SexQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import time as timer\n",
        "from datetime import timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAW5roT3Rcw7"
      },
      "outputs": [],
      "source": [
        "# ƒê·ªãnh nghƒ©a k√≠ch th∆∞·ªõc c·ªßa c·ª≠a s·ªï d·ªØ li·ªáu\n",
        "window_size = 4\n",
        "\n",
        "# T·∫°o ra m·ªôt d√£y gi√° tr·ªã t·ª´ 0 ƒë·∫øn 9 (bao g·ªìm c·∫£ 9)\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "# Hi·ªÉn th·ªã d·ªØ li·ªáu\n",
        "print(f\"D·ªØ li·ªáu th√¥:\\n{dataset}\")\n",
        "for d in dataset:\n",
        "  print(d.numpy(), end=\", \")\n",
        "print() # ƒê·ªÉ xu·ªëng h√†ng\n",
        "\n",
        "# D√πng c·ª≠a s·ªï tr∆∞·ª£t ƒë·ªÉ t·∫°o ra c√°c c·ª≠a s·ªï d·ªØ li·ªáu\n",
        "dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "# Ch√∫ng ta c·ªông 1 v√†o ƒë·∫°i di·ªán cho nh√£n c·ªßa c·ª≠a s·ªï ƒë√≥, m·ªôt ch·∫≠p ch√∫ng ta s·∫Ω c·∫Øt ra\n",
        "# shift l√† s·ªë √¥ tr∆∞·ª£t trong m·ªôt l·∫ßn, drop_remainder ƒë·ªÉ t·ª± ƒë·ªông lo·∫°i b·ªè c√°c c·ª≠a s·ªï c√≥ s·ªë gi√° tr·ªã nh·ªè h∆°n k√≠ch th∆∞·ªõc\n",
        "# Hi·ªÉn th·ªã d·ªØ li·ªáu\n",
        "print(f\"\\nD·ªØ li·ªáu sau khi √°p d·ª•ng c·ª≠a s·ªï tr∆∞·ª£t:\\n{dataset}\")\n",
        "for window_dataset in dataset:\n",
        "    # window_dataset l√† m·ªôt Dataset ch·ª©a c√°c ph·∫ßn t·ª≠ c·ªßa m·ªôt c·ª≠a s·ªï\n",
        "    window_values = list(window_dataset.as_numpy_iterator())  # Tr√≠ch xu·∫•t d·ªØ li·ªáu\n",
        "    print(window_values)\n",
        "\n",
        "# D√πng batch chuy·ªÉn ki·ªÉu d·ªØ li·ªáu t·ª´ dataset th√†nh tensorflow th√¥ng th∆∞·ªùng\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "# Hi·ªÉn th·ªã d·ªØ li·ªáu\n",
        "print(f\"\\nD·ªØ li·ªáu sau khi √°p d·ª•ng batch:\\n{dataset}\")\n",
        "for window in dataset:\n",
        "  print(window.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEZY2RSfUKqE"
      },
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ d·ªØ li·ªáu c·ªßa t·ª•i m√¨nh nha.\n",
        "\n",
        "\n",
        "```python\n",
        "[0 1 2 3 4]\n",
        "[1 2 3 4 5]\n",
        "[2 3 4 5 6]\n",
        "[3 4 5 6 7]\n",
        "[4 5 6 7 8]\n",
        "[5 6 7 8 9]\n",
        "```\n",
        "\n",
        "Sau khi ƒë√£ chia th√†nh c√°cc c·ª≠a s·ªï d·ªØ li·ªáu r·ªìi, t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh chia ph·∫ßn ƒë·∫∑c tr∆∞ng v√† nh√£n ·ªü c√°c c·ª≠a s·ªï ra nha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ojn9o6YjfNxI"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "# Hi·ªÉn th·ªã d·ªØ li·ªáu\n",
        "print(f\"\\nD·ªØ li·ªáu sau khi chia ƒë·∫∑c tr∆∞ng v√† nh√£n:\\n{dataset}\")\n",
        "for x, y in dataset:\n",
        "  print(x.numpy(), y.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUivL8eAfem-"
      },
      "source": [
        "Sau ƒë√≥, ta ti·∫øn h√†nh x√°o tr·ªôn d·ªØ li·ªáu l√™n v√† chia ra c√°c l√¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d5bfVlATs3U"
      },
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "dataset = dataset.shuffle(10).batch(batch_size).prefetch(1)\n",
        "# prefetch gi√∫p tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω d·ªØ li·ªáu trong qu√° tr√¨nh song song h√≥a, ·ªü hi·ªán t·∫°i s·∫Ω ƒë∆∞a tr∆∞·ªõc 1 batch v√†o.\n",
        "\n",
        "# Hi·ªÉn th·ªã d·ªØ li·ªáu\n",
        "for x,y in dataset:\n",
        "  print(\"x = \", x.numpy())\n",
        "  print(\"y = \", y.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klvtQiychZvk"
      },
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ c·ªßa t·ª•i m√¨nh.\n",
        "\n",
        "```\n",
        "x =  [[2 3 4 5]\n",
        " [5 6 7 8]]\n",
        "y =  [[6]\n",
        " [9]]\n",
        "x =  [[1 2 3 4]\n",
        " [4 5 6 7]]\n",
        "y =  [[5]\n",
        " [8]]\n",
        "x =  [[3 4 5 6]\n",
        " [0 1 2 3]]\n",
        "y =  [[7]\n",
        " [4]]\n",
        "```\n",
        "\n",
        "M·ªçi ng∆∞·ªùi c√≥ th·ªÉ th·∫•y d·ªØ li·ªáu chia th√†nh danh s√°ch c√°c l√¥ (batch) v·ªõi m·ªói batch c√≥ 2 m·∫´u.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGKB4oFZhsK_"
      },
      "source": [
        "# Creating a Windowed Version of the Time Series Dataset üåü\n",
        "\n",
        "B√¢y gi·ªù t·ª•i m√¨nh ti·∫øn h√†nh √°p d·ª•ng ph∆∞∆°ng ph√°p c·ª≠a s·ªï tr∆∞·ª£t n√†y tr√™n d·ªØ li·ªáu th·ªùi gian ƒë√£ t·∫°o ·ªü ch∆∞∆°ng 9 ƒë·ªÉ t·∫°o ra **windowed dataset** nha. üíª‚ú®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yta85x-XhZNv"
      },
      "outputs": [],
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "  \"\"\"\n",
        "  H√†m n√†y d√πng ƒë·ªÉ v·∫Ω d·ªØ li·ªáu chu·ªói th·ªùi gian trong m·ªôt khung th·ªùi gian\n",
        "\n",
        "  Tham s·ªë ƒë·∫ßu v√†o:\n",
        "  - time: kho·∫£ng th·ªùi gian x·∫£y ra\n",
        "  - series: chu·ªói gi√° tr·ªã t∆∞∆°ng ·ª©ng trong th·ªùi gian ƒë√≥\n",
        "  - start: th·ªùi gian b·∫Øt ƒë·∫ßu\n",
        "  - end: th·ªùi gian k·∫øt th√∫c\n",
        "  \"\"\"\n",
        "\n",
        "  plt.plot(time[start:end], series[start:end], format)\n",
        "  plt.xlabel(\"Time\")\n",
        "  plt.ylabel(\"Value\")\n",
        "  plt.grid(True)\n",
        "\n",
        "\n",
        "def trend(time, slope=0):\n",
        "  \"\"\"\n",
        "  H√†m n√†y gi√∫p ƒëi·ªÅu h∆∞·ªõng xu h∆∞·ªõng c·ªßa d·ªØ li·ªáu, gi·ªëng v·ªõi ph∆∞∆°ng tr√¨nh b·∫≠c 1\n",
        "\n",
        "  Tham s·ªë ƒë·∫ßu v√†o:\n",
        "  - time: kho·∫£ng th·ªùi gian x·∫£y ra\n",
        "  - slope: ƒë·ªô d·ªëc c·ªßa d·ªØ li·ªáu.\n",
        "    + N·∫øu gi√° tr·ªã d∆∞∆°ng th√¨ ƒë∆∞·ªùng th·∫≥ng h∆∞·ªüng l√™n, ta c√≥ xu h∆∞·ªõng Uptrend\n",
        "    + N·∫øu gi√° tr·ªã √¢m th√¨ ch√∫ng ta c√≥ xu h∆∞·ªõng Downtrend\n",
        "\n",
        "  K·∫øt qu·∫£ tr·∫£ v·ªÅ:\n",
        "  - series: danh s√°ch gi√° tr·ªã theo xu h∆∞·ªõng th·ªùi gian\n",
        "  \"\"\"\n",
        "  return slope * time\n",
        "\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "  \"\"\"\n",
        "  H√†m n√†y d√πng ƒë·ªÉ t·∫°o ra m·∫´u d·ªØ li·ªáu trong 1 m√πa.\n",
        "  ·ªû ƒë√¢y m√¨nh chia l√†m 2 pha t√≠nh, logic t√≠nh to√°n nh∆∞ sau nha:\n",
        "  - N·∫øu th·ªùi gian m√πa < 0.4, ti·∫øn h√†nh t√≠nh theo dao ƒë·ªông cosine: np.cos(season_time *2 *np.pi)\n",
        "  - N·∫øu th·ªùi gian m√πa > 0.4, ti·∫øn h√†nh t√≠nh theo h√†m suy gi·∫£m m≈©:  1 / np.exp(3 * season_time)\n",
        "\n",
        "  Tham s·ªë ƒë·∫ßu v√†o:\n",
        "  - th·ªùi gian c·ªßa m√πa\n",
        "\n",
        "  K·∫øt qu·∫£ tr·∫£ v·ªÅ:\n",
        "  - res: k·∫øt qu·∫£ t√≠nh ra ƒë∆∞·ª£c t·ª´ logic t√≠nh to√°n n·∫±m trong kho·∫£ng [-1, 1]\n",
        "  \"\"\"\n",
        "  res = np.where(season_time<0.4,\n",
        "                 np.cos(season_time * 2 * np.pi),\n",
        "                 1 / np.exp(3 * season_time))\n",
        "  return res\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "  \"\"\"\n",
        "  H√†m n√†y ƒë·ªÉ l·∫∑p l·∫°i, t·∫°o n√™n th·ªùi gian cho c√°c m√πa nha.\n",
        "  Logic t√≠nh to√°n s·∫Ω nh∆∞ sau:\n",
        "  - time % period s·∫Ω ra gi√° tr·ªã trong kho·∫£ng [0, period - 1] -> t·∫°o ra ƒë∆∞·ª£c c√°c l·∫ßn l·∫∑p th·ªùi gian c·ªßa m√πa [0->period-1, 0->period-1,...]\n",
        "  - / period s·∫Ω ti·∫øn h√†nh chu·∫©n h√≥a l·∫°i th·ªùi gian c·ªßa m√πa v·ªÅ kho·∫£ng [0, 1]\n",
        "  - Ch·∫°y seasion time v√¥ h√†m seasonal_pattern ƒë·ªÉ t·∫°o ra chu·ªói gi√° tr·ªã t∆∞∆°ng ·ª©ng v·ªõi d√£y th·ªùi gian c·ªßa c√°c m√πa, gi√° tr·ªã n·∫±m trong kho·∫£ng [-1, 1]\n",
        "  - amplitude * seasonal_pattern, ta ti·∫øn h√†nh nh√¢n bi√™n ƒë·ªô dao ƒë·ªông v·ªõi chu·ªói gi√° tr·ªã th√¨ gi√° tr·ªã cu·ªëi c√πng s·∫Ω trong kho·∫£ng [-amplitude, amplitude]\n",
        "\n",
        "  Tham s·ªë ƒë·∫ßu v√†o:\n",
        "  - time: kho·∫£ng th·ªùi gian x·∫£y ra\n",
        "  - period: kho·∫£ng th·ªùi gian c·ªßa m·ªôt m√πa\n",
        "  - amplitude: bi√™n ƒë·ªô dao ƒë·ªông t·ªëi ƒëa c·ªßa d·ªØ li·ªáu, v√≠ d·ª• m√¨nh ƒë·ªÉ l√† 15 th√¨ s·∫Ω dao ƒë·ªông trong kho·∫£ng gi√° tr·ªã t·ª´ -15 ƒë·∫øn 15\n",
        "  - phase: ƒë·ªô l·ªách pha, v√≠ d·ª• n·∫øu ta g√°n 15, thay v√¨ m√πa v·ª• b·∫Øt ƒë·∫ßu t·ª´ th·ªùi ƒëi·ªÉm t = 0 th√¨ b·ªã l·ªách ƒëi 15 b∆∞·ªõc th·ªùi gian t·ª©c b·∫Øt ƒë·∫ßu v√†o t = 15\n",
        "\n",
        "  K·∫øt qu·∫£ tr·∫£ v·ªÅ:\n",
        "  - res: d·ªØ li·ªáu mang t√≠nh chu k·ª≥, m√πa v·ª•\n",
        "  \"\"\"\n",
        "  season_time = ((time + phase) % period) / period\n",
        "  res = amplitude * seasonal_pattern(season_time)\n",
        "  return res\n",
        "\n",
        "\n",
        "def noise(time, noise_level=1, seed=None):\n",
        "  \"\"\"\n",
        "  H√†m n√†y ƒë·ªÉ t·∫°o t√≠nh nhi·ªÖu cho d·ªØ li·ªáu\n",
        "  Logic t√≠nh to√°n nh∆∞ sau:\n",
        "  - rnd.rand(len(time)) tr·∫£ v·ªÅ m·ªôt d√£y gi√° tr·ªã c√≥ ƒë·ªô l·ªõn trong kho·∫£ng [0,1),\n",
        "   s·ªë l∆∞·ª£ng gi√° tr·ªã b·∫±ng s·ªë b∆∞·ªõc th·ªùi gian\n",
        "  - Sau ƒë√≥ nh√¢n v·ªõi noise_level s·∫Ω ra gi√° tr·ªã trong kho·∫£ng [0, noise_level)\n",
        "\n",
        "  Tham s·ªë ƒë·∫ßu v√†o:\n",
        "  - time: kho·∫£ng th·ªùi gian x·∫£y ra.\n",
        "  - noise_level: c·∫•p ƒë·ªô nhi·ªÖu c·ªßa d·ªØ li·ªáu\n",
        "  - seed: n·∫øu ƒë·ªÉ gi√° tr·ªã kh√°c None, th√¨ ·ªü c√°c l·∫ßn ch·∫°y sau,\n",
        "  khi gi√° tr·ªã seed b·∫±ng nhau th√¨ gi√° tr·ªã ng·∫´u nhi√™n t·∫°o ra c≈©ng b·∫±ng nhau\n",
        "\n",
        "  K·∫øt qu·∫£ ƒë·∫ßu ra:\n",
        "  - res: d·ªØ li·ªáu mang t√≠nh nhi·∫øu\n",
        "  \"\"\"\n",
        "  rnd = np.random.RandomState(seed)\n",
        "  res = rnd.rand(len(time)) * noise_level\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE1O-gY6iLrF"
      },
      "outputs": [],
      "source": [
        "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
        "# series = trend(time, 0.1)\n",
        "# baseline = 10\n",
        "# amplitude = 15\n",
        "# slop = 0.09\n",
        "# noise_level = 15\n",
        "# period = 360\n",
        "\n",
        "series = trend(time, 0.1)\n",
        "baseline = 10\n",
        "amplitude = 20\n",
        "slop = 0.09\n",
        "noise_level = 5\n",
        "period = 360\n",
        "\n",
        "series = baseline + trend(time, slop)\n",
        "series += seasonality(time, period=period, amplitude=amplitude)\n",
        "series += noise(time, noise_level, seed=42)\n",
        "plot_series(time, series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZmvNN86jlD6"
      },
      "outputs": [],
      "source": [
        "# Ti·∫øn h√†nh t·∫°o \"windowed dataset\"\n",
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK8kWsFrkU3t"
      },
      "outputs": [],
      "source": [
        "split_time = 1000\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]\n",
        "\n",
        "window_size = 20\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000\n",
        "\n",
        "train_dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "val_dataset = windowed_dataset(x_valid, window_size, batch_size, shuffle_buffer_size)\n",
        "print(train_dataset)\n",
        "\n",
        "for feature, label in train_dataset.take(1):\n",
        "  print(feature.numpy())\n",
        "  print(label.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEoZh_A_k9wd"
      },
      "outputs": [],
      "source": [
        "# Ti·∫øn h√†nh ƒë·ªãnh nghƒ©a m√¥ h√¨nh\n",
        "model = Sequential([\n",
        "  tf.keras.layers.Dense(10, input_shape=[window_size], activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC-5MOlMmKR8"
      },
      "outputs": [],
      "source": [
        "# Ti·∫øn h√†nh hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkbyalm0n2M-"
      },
      "outputs": [],
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì hu·∫•n luy·ªán\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(loss, label='Training loss')\n",
        "plt.plot(val_loss, label='Validation loss')\n",
        "plt.axis([0, 100, 0, 100]) # V·∫Ω bi·ªÉu ƒë·ªì trong kho·∫£ng n√†y\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPb88jWtMsbh"
      },
      "source": [
        "# Evaluating the Results of the DNN üìä\n",
        "\n",
        "Sau khi hu·∫•n luy·ªán m√¥ h√¨nh, t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh d·ª± ƒëo√°n th·ª≠ v√† ƒë√°nh gi√° nha. C√≥ m·ªôt l∆∞u √Ω nh·ªè l√† v√¨ d·ªØ li·ªáu hu·∫•n luy·ªán c·ªßa ch√∫ng ta ƒë∆∞·ª£c t·∫°o ra b·∫±ng ph∆∞∆°ng ph√°p c·ª≠a s·ªï tr∆∞·ª£t n√™n chu·ªói d·ªØ li·ªáu ƒë∆∞a v√†o m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n c≈©ng ph·∫£i c√≥ ƒë·ªô d√†i t∆∞∆°ng t·ª± c·ª≠a s·ªï tr∆∞·ª£t nha. üîç\n",
        "\n",
        "ƒê·ªÉ d·ª± ƒëo√°n gi√° tr·ªã t·∫°i m·ªôt th·ªùi ƒëi·ªÉm, ta c·∫ßn cung c·∫•p chu·ªói gi√° tr·ªã t·ª´ th·ªùi ƒëi·ªÉm **t** ƒë·∫øn **t + window_size**. üìà\n",
        "\n",
        "**VD:** Ta c·∫ßn d·ª± ƒëo√°n gi√° tr·ªã t·∫°i th·ªùi ƒëi·ªÉm **t = 1020** v·ªõi k√≠ch th∆∞·ªõc c·ª≠a s·ªï l√† 20, ta c·∫ßn chu·ªói gi√° tr·ªã t·ª´ th·ªùi ƒëi·ªÉm **t = 1000 ƒë·∫øn 1019**. üåü"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i2gWmMBRxbM"
      },
      "outputs": [],
      "source": [
        "start_point = 1000\n",
        "print(f\"Chu·ªói gi√° tr·ªã d√πng ƒë·ªÉ d·ª± ƒëo√°n:\\n{series[start_point:start_point + window_size]}\")\n",
        "print(f\"Gi√° tr·ªã th·ª±c t·∫ø: {series[start_point + window_size]}\")\n",
        "print(f\"Gi√° tr·ªã d·ª± ƒëo√°n: {model.predict(series[start_point:start_point + window_size][np.newaxis])}\")\n",
        "# D√πng np.newaxis ƒë·ªÉ ƒë·ªãnh d·∫°ng l·∫°i k√≠ch th∆∞·ªõc (shape) d·ªØ li·ªáu ƒë·∫ßu v√†o t·ª´ [window_size] sang [1, window_size]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOrRhWEdUGha"
      },
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha.\n",
        "\n",
        ">Gi√° tr·ªã th·ª±c t·∫ø: 107.13153076171875   \n",
        "Gi√° tr·ªã d·ª± ƒëo√°n: [[106.628136]]\n",
        "\n",
        "U·∫ßy gi√° tr·ªã c≈©ng kh√° s√°t nhau ha.   \n",
        "B√¢y gi·ªù t·ª•i m√¨nh ƒë·∫øn v·ªõi ph·∫ßn ti·∫øp theo, t√¨m hi·ªÉu v·ªÅ c√°c ph∆∞∆°ng ph√°p ƒëo l∆∞·ªùng trong su·ªët th·ªùi gian ha."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2xMohpbUjkZ"
      },
      "source": [
        "# Exploring the Overall Prediction üîç\n",
        "\n",
        "B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh d·ª± ƒëo√°n gi√° tr·ªã t·∫°i t·∫•t c·∫£ b∆∞·ªõc th·ªùi gian ƒë·ªÉ quan s√°t k·∫øt qu·∫£ t·ªïng qu√°t c·ªßa m√¥ h√¨nh ha. üìà‚ú®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rygytl5YU2Pf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "forecast = []\n",
        "for t in range(len(series) - window_size): # Tr·ª´ window_size v√¨ ch√∫ng ta c·∫ßn d√πng m·ªôt s·ªë l∆∞·ª£ng d·ªØ li·ªáu ban ƒë·∫ßu ƒë·ªÉ d·ª± ƒëo√°n\n",
        "  forecast.append(\n",
        "      model.predict(series[t:t + window_size][np.newaxis], verbose = 0)\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C√≥ m·ªôt ƒëi·ªÉm nh·ªè m√† b·∫°n c√≥ th·ªÉ r√∫t ra ƒë∆∞·ª£c l√† ch√∫ng ta s·∫Ω kh√¥ng th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c n gi√° tr·ªã t∆∞∆°ng ·ª©ng v·ªõi k√≠ch th∆∞·ªõc c·ªßa c·ª≠a s·ªï d·ªØ li·ªáu b·ªüi ch√∫ng ta c·∫ßn d√πng n gi√° tr·ªã kh·ªüi ƒë·∫•u ƒë·ªÉ d·ª± ƒëo√°n."
      ],
      "metadata": {
        "id": "ZtfTn2EMWlIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì d·ª± ƒëo√°n ·ªü t·∫≠p val t√≠nh t·ª´ th·ªùi ƒëi·ªÉm t = 1000\n",
        "forecast_val = forecast[start_point - window_size:] # Ch√∫ng ta c·∫ßn tr·ª´ ƒëi windown_size do index b·ªã l·ªách ƒëi b·ªüi kh√¥ng th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c n gi√° t·ªã kh·ªüi ƒë·∫ßu.\n",
        "results = np.array(forecast_val)[:, 0, 0]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, results)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "UC555RIPWfJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U·∫ßy, k·∫øt qu·∫£ kh√¥ng t·ªá ha. üòÑ K·∫øt qu·∫£ d·ª± ƒëo√°n c√≥ th·ªÉ b√°m s√°t ƒë∆∞·ª£c v·ªõi ƒë∆∞·ªùng cong c·ªßa gi√° tr·ªã th·ª±c t·∫ø. Tuy l√† ·ªü nh·ªØng ch·ªó gi√° tr·ªã thay ƒë·ªïi ƒë·ªôt ng·ªôt, m√¥ h√¨nh hay gi√° tr·ªã d·ª± ƒëo√°n c·∫ßn m·ªôt √≠t th·ªùi gian ƒë·ªÉ theo k·ªãp, nh∆∞ng th·∫≠t s·ª± k·∫øt qu·∫£ n√†y c≈©ng kh√° tuy·ªát r·ªìi. üåü\n",
        "\n",
        "B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω s·ª≠ d·ª•ng **MAE** ƒë·ªÉ ƒë√°nh gi√° hi·ªáu qu·∫£ c·ªßa m√¥ h√¨nh d·ª±a tr√™n k·∫øt qu·∫£ d·ª± ƒëo√°n nha. üìä‚ú®"
      ],
      "metadata": {
        "id": "k4xsERpKY1DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "print(f\"MAE c·ªßa m√¥ h√¨nh: {keras.metrics.mean_absolute_error(x_valid, results).numpy()}\")"
      ],
      "metadata": {
        "id": "DNERUu6UbFVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha:\n",
        ">MAE c·ªßa m√¥ h√¨nh: 2.091493844985962"
      ],
      "metadata": {
        "id": "ukEPrwQrdm0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "V·∫≠y c√¥ng vi·ªác ti·∫øp theo c·ªßa t·ª•i m√¨nh ƒë·ªÉ t·ªëi ∆∞u h√≥a m√¥ h√¨nh l√† gi·∫£m thi·ªÉu ch·ªâ s·ªë **MAE** xu·ªëng th·∫•p nh·∫•t c√≥ th·ªÉ. üéØ Ch√∫ng ta c√≥ th·ªÉ th·ª±c hi·ªán vi·ªác t·ªëi ∆∞u h√≥a n√†y b·∫±ng nhi·ªÅu c√°ch kh√°c nhau, m√† ƒëi·ªÉn h√¨nh l√† tinh ch·ªânh c√°c si√™u tham s·ªë c·ªßa m√¥ h√¨nh. üîß‚ú®\n",
        "\n",
        "ƒê·∫øn v·ªõi ph·∫ßn ti·∫øp theo, t·ª•i m√¨nh s·∫Ω t√¨m hi·ªÉu v·ªÅ c√°c c√¥ng c·ª• c≈©ng nh∆∞ b·ªô t·ªëi ∆∞u h√≥a ƒë·ªÉ h·ªó tr·ª£ th·ª±c hi·ªán vi·ªác t·ªëi ∆∞u h√≥a m√¥ h√¨nh thu·∫≠n ti·ªán h∆°n. üöÄ"
      ],
      "metadata": {
        "id": "CPpVVt95dxvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning the Learning Rate üîÑ\n",
        "\n",
        "ƒê·∫øn v·ªõi ph·∫ßn n√†y, t·ª•i m√¨nh s·∫Ω hi·ªáu ch·ªânh t·ªëc ƒë·ªô h·ªçc c·ªßa m√¥ h√¨nh nha. üéØ\n",
        "\n",
        "·ªû v√≠ d·ª• tr∆∞·ªõc ƒë√≥, t·ª•i m√¨nh ƒë√£ ti·∫øn h√†nh bi√™n d·ªãch m√¥ h√¨nh nh∆∞ sau:\n",
        "\n",
        "```python\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9))\n",
        "```\n",
        "\n",
        "Tuy nhi√™n, con s·ªë **1e-6** n√†y c√≥ v·∫ª kh√° ng·∫´u nhi√™n ha, kh√¥ng c√≥ m·ªôt cƒÉn c·ª© c·ª• th·ªÉ n√†o c·∫£. ü§î  \n",
        "\n",
        "> **V·∫≠y l√†m th·∫ø n√†o ƒë·ªÉ c√≥ th·ªÉ ch·ªçn ra learning rate m·ªôt c√°ch h·ª£p l√Ω?**\n",
        "\n",
        "R·∫•t may l√† trong TensorFlow c√≥ s·∫µn h√†m ƒë·ªÉ th·ª±c hi·ªán vi·ªác n√†y. üõ†Ô∏è Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng n√≥ th√¥ng qua **callback**. M·ªçi ng∆∞·ªùi c√≥ th·ªÉ nh·ªõ l·∫°i m·ªôt ch√∫t, ch√∫ng ta ƒë√£ t·ª´ng ti·∫øp x√∫c v·ªõi **callback** ·ªü ch∆∞∆°ng 2 r·ªìi √°, v·ªõi c∆° ch·∫ø **early_stopping**. ‚è≥"
      ],
      "metadata": {
        "id": "3KBbMxXyeP2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh l√™n l·ªãch ƒëi·ªÅu ch·ªânh cho learning rate v·ªõi ƒëo·∫°n code d∆∞·ªõi ƒë√¢y"
      ],
      "metadata": {
        "id": "xz2-UqGMhq4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "lr_schedule = LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch / 20))"
      ],
      "metadata": {
        "id": "aF6Dwzylhy-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "·ªû h√†m tr√™n, ch√∫ng ta ti·∫øn h√†nh ƒë·ªãnh nghƒ©a gi√° tr·ªã kh·ªüi t·∫°o ban ƒë·∫ßu c·ªßa **learning rate** b·∫±ng **1e-8**, sau ƒë√≥ s·∫Ω tƒÉng d·∫ßn l√™n. üîÑ M·ªói l·∫ßn **epoch** tƒÉng l√™n ƒë·∫øn c√°c m·ªëc chia h·∫øt cho 20, th√¨ **learning rate** tƒÉng l√™n g·∫•p 10 l·∫ßn. üìà\n",
        "\n",
        "B√¢y gi·ªù, ch√∫ng ta s·∫Ω ti·∫øn h√†nh r√°p l·∫°i v√†o m√¥ h√¨nh nha. üõ†Ô∏è‚ú®"
      ],
      "metadata": {
        "id": "P9wumbeNiB-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  tf.keras.layers.Dense(10, input_shape=[window_size], activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-8, momentum=0.9)\n",
        "model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "history = model.fit(train_dataset, epochs=100, callbacks=[lr_schedule], validation_data=val_dataset)"
      ],
      "metadata": {
        "id": "fRjO8iraigJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì ƒë√°nh gi√° loss tr√™n c√°c learning rate\n",
        "lrs = 1e-8 * (10 ** (np.arange(100) / 20))\n",
        "plt.semilogx(lrs, history.history[\"loss\"])\n",
        "plt.axis([1e-8, 1e-3, 0, 300])"
      ],
      "metadata": {
        "id": "L9Eb7p_BjI9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh."
      ],
      "metadata": {
        "id": "3cx1-l2qnH_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![optimizing_learning_rate](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_10/optimize_learning_rate.png?raw=true)"
      ],
      "metadata": {
        "id": "FnFOtpX0LjHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nh√¨n c√≥ v·∫ª ch·ªâ s·ªë learning rate **1e-5** c√≥ v·∫ª th·∫•p h∆°n t√≠. T·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi learning rate = 1e-5 v√† ƒë√°nh gi√° l·∫°i th·ª≠ nha."
      ],
      "metadata": {
        "id": "QzZcwH6ZnPVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  tf.keras.layers.Dense(10, input_shape=[window_size], activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9)\n",
        "model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=val_dataset)"
      ],
      "metadata": {
        "id": "SB878FLdm6Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bi·ªÉu di·ªÖn qu√° tr√¨nh hu·∫•n luy·ªán\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "skqTsHgdn_-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U·∫ßy k·∫øt qu·∫£ loss ·ªü l·ªõp cu·ªëi c√πng b·∫±ng 5.9828 th·∫•p h∆°n m·ªôt x√≠u so v·ªõi m√¥ h√¨nh s·ª≠ d·ª•ng learing rate b·∫±ng 1e-6 ha."
      ],
      "metadata": {
        "id": "VG-O_ipEqsx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecast = []\n",
        "for t in range(len(series) - window_size): # Tr·ª´ window_size v√¨ ch√∫ng ta c·∫ßn d√πng m·ªôt s·ªë l∆∞·ª£ng d·ªØ li·ªáu ban ƒë·∫ßu ƒë·ªÉ d·ª± ƒëo√°n\n",
        "  forecast.append(\n",
        "      model.predict(series[t:t + window_size][np.newaxis], verbose = 0)\n",
        "  )"
      ],
      "metadata": {
        "id": "8nP4Cgaerv2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì d·ª± ƒëo√°n ·ªü t·∫≠p val t√≠nh t·ª´ th·ªùi ƒëi·ªÉm t = 1000\n",
        "forecast_val = forecast[start_point - window_size:] # Ch√∫ng ta c·∫ßn tr·ª´ ƒëi windown_size do index b·ªã l·ªách ƒëi b·ªüi kh√¥ng th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c n gi√° t·ªã kh·ªüi ƒë·∫ßu.\n",
        "results = np.array(forecast_val)[:, 0, 0]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, results)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "iD6EDYyarb8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh ƒë√°nh gi√° MAE\n",
        "print(f\"MAE c·ªßa m√¥ h√¨nh: {keras.metrics.mean_absolute_error(x_valid, results).numpy()}\")"
      ],
      "metadata": {
        "id": "cVS7xVJErLxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuy nhi√™n k·∫øt qu·∫£ ƒë√°nh gi√° l·∫°i c√≥ ph·∫ßn t·ªá h∆°n:\n",
        "> 1e-6: 2.091493844985962   \n",
        "1e-5: 2.671138048171997"
      ],
      "metadata": {
        "id": "z3vaRxrEsQo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kh√¥ng sao, √≠t nh·∫•t th√¨ t·ª•i m√¨nh c≈©ng ƒë√£ t√¨m ra ƒë∆∞·ª£c **learning_rate** t·ªët nh·∫•t r·ªìi. üéØ B√¢y gi·ªù, h√£y th·ª≠ m·ªü r·ªông ra v√† t√¨m hi·ªÉu th√™m nhi·ªÅu ph∆∞∆°ng ph√°p kh√°c ƒë·ªÉ t·ªëi ∆∞u h√≥a xem. M·ªôt trong nh·ªØng c√°ch d·ªÖ nh·∫•t m√† t·ª•i m√¨nh c√≥ th·ªÉ suy nghƒ© ƒë·∫øn l√† **tƒÉng k√≠ch th∆∞·ªõc c·ª≠a s·ªï tr∆∞·ª£t**, ƒë·ªÉ m√¥ h√¨nh c√≥ th·ªÉ h·ªçc nhi·ªÅu h∆°n t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o. üìä‚ú®\n",
        "\n",
        "·ªû ƒë√¢y, m√¨nh s·∫Ω ti·∫øn h√†nh tƒÉng k√≠ch th∆∞·ªõc c·ª≠a s·ªï tr∆∞·ª£t l√™n **40** ƒë·ªÉ xem th·ª≠ k·∫øt qu·∫£ nha. üöÄ"
      ],
      "metadata": {
        "id": "l0pcxMAx7RML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_time = 1000\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]\n",
        "\n",
        "window_size = 40\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000\n",
        "\n",
        "train_dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "val_dataset = windowed_dataset(x_valid, window_size, batch_size, shuffle_buffer_size)\n",
        "print(train_dataset)\n",
        "\n",
        "for feature, label in train_dataset.take(1):\n",
        "  print(feature.numpy())\n",
        "  print(label.numpy())"
      ],
      "metadata": {
        "id": "U1Y1gYNI8UrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  tf.keras.layers.Dense(10, input_shape=[window_size], activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9)\n",
        "model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=val_dataset)"
      ],
      "metadata": {
        "id": "Cz4R9GIC8mP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bi·ªÉu di·ªÖn qu√° tr√¨nh hu·∫•n luy·ªán\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bieaQlFL9Jw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast = []\n",
        "for t in range(len(series) - window_size): # Tr·ª´ window_size v√¨ ch√∫ng ta c·∫ßn d√πng m·ªôt s·ªë l∆∞·ª£ng d·ªØ li·ªáu ban ƒë·∫ßu ƒë·ªÉ d·ª± ƒëo√°n\n",
        "  forecast.append(\n",
        "      model.predict(series[t:t + window_size][np.newaxis], verbose = 0)\n",
        "  )"
      ],
      "metadata": {
        "id": "LrS52rWXf4WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì d·ª± ƒëo√°n ·ªü t·∫≠p val t√≠nh t·ª´ th·ªùi ƒëi·ªÉm t = 1000\n",
        "forecast_val = forecast[start_point - window_size:] # Ch√∫ng ta c·∫ßn tr·ª´ ƒëi windown_size do index b·ªã l·ªách ƒëi b·ªüi kh√¥ng th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c n gi√° t·ªã kh·ªüi ƒë·∫ßu.\n",
        "results = np.array(forecast_val)[:, 0, 0]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, results)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "QzJ8kFVe9Mw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh ƒë√°nh gi√° MAE\n",
        "print(f\"MAE c·ªßa m√¥ h√¨nh: {keras.metrics.mean_absolute_error(x_valid, results).numpy()}\")"
      ],
      "metadata": {
        "id": "J_JJjF7z9N5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U·∫ßy k·∫øt qu·∫£ c·∫£i thi·ªán r√µ r·ªát nha\n",
        "> MAE c·ªßa m√¥ h√¨nh: 1.9043922424316406"
      ],
      "metadata": {
        "id": "FrWKHvvsFFkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Hyperparameter Tuning with Keras Tuner üîß‚ú®\n",
        "\n",
        "B√¢y gi·ªù, t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh t·ªëi ∆∞u h√≥a c√°c si√™u tham s·ªë v·ªõi c√¥ng c·ª• **Keras Tuner** nha. üöÄ\n",
        "\n",
        "N√≥i ƒë∆°n gi·∫£n, v·ªõi m·ªói si√™u tham s·ªë, ch√∫ng ta s·∫Ω c√≥ v√†i l·ª±a ch·ªçn. Khi thay ƒë·ªïi nhi·ªÅu si√™u tham s·ªë, ch√∫ng s·∫Ω t·∫°o ra s·ªë t·ªï h·ª£p l·ª±a ch·ªçn v√¥ c√πng l·ªõn m√† ch√∫ng ta c·∫ßn ph·∫£i th·ª≠ nghi·ªám. üîÑ ƒêi·ªÅu n√†y ƒë·ªìng nghƒ©a v·ªõi vi·ªác ph·∫£i thi·∫øt k·∫ø m√¥ h√¨nh cho t·ª´ng t·ªï h·ª£p si√™u tham s·ªë v√† hu·∫•n luy·ªán t·ª´ng c√°i m·ªôt. üß™\n",
        "\n",
        "Vi·ªác n√†y kh√° r·∫Øc r·ªëi v√† t·ªën r·∫•t nhi·ªÅu th·ªùi gian. ‚è≥ Do ƒë√≥, ƒë·ªÉ ti·ªán cho vi·ªác l·∫≠p tr√¨nh v√† th·ª≠ nghi·ªám, c√¥ng c·ª• **Keras Tuner** ƒë∆∞·ª£c ra ƒë·ªùi. üåü"
      ],
      "metadata": {
        "id": "AMPonQOZ9ZH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫£i b·ªô c√¥ng c·ª•\n",
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "id": "F0k6uLZN9XqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "S∆° l∆∞·ª£c v·ªÅ c√¥ng c·ª• **Keras Tuner**, n√≥ s·∫Ω gi√∫p ch√∫ng ta th·ª≠ nghi·ªám h√†ng lo·∫°t c√°c si√™u tham s·ªë th√¥ng qua vi·ªác ch·ªâ ƒë·ªãnh ph·∫°m vi gi√° tr·ªã ho·∫∑c c√°c gi√° tr·ªã c·∫ßn th·ª≠ nghi·ªám. üîÑ Sau ƒë√≥, c√¥ng c·ª• n√†y s·∫Ω ti·∫øn h√†nh hu·∫•n luy·ªán m·ªôt lo·∫°t c√°c m√¥ h√¨nh d·ª±a tr√™n t·ª´ng t·ªï h·ª£p si√™u tham s·ªë v√† tr·∫£ v·ªÅ c√°c m√¥ h√¨nh c√≥ k·∫øt qu·∫£ ƒë√°nh gi√° t·ªët nh·∫•t. üìä‚ú®\n",
        "\n",
        "T·∫•t nhi√™n, m·ªçi ng∆∞·ªùi c≈©ng c√≥ th·ªÉ ch·ªâ ƒë·ªãnh c√°c thang ƒëo ri√™ng ƒë·ªÉ ƒë√°nh gi√° k·∫øt qu·∫£, t√πy thu·ªôc v√†o m·ª•c ti√™u c·ª• th·ªÉ c·ªßa m√¨nh. üéØ\n",
        "\n",
        "B√¢y gi·ªù, t·ª•i m√¨nh ƒëi v√†o v√≠ d·ª• ƒë·ªÉ d·ªÖ hi·ªÉu h∆°n nha. Th√¥ng th∆∞·ªùng, t·ª•i m√¨nh s·∫Ω ƒë·ªãnh nghƒ©a m·ªôt l·ªõp **dense** nh∆∞ ƒëo·∫°n code d∆∞·ªõi ƒë√¢y:\n",
        "\n",
        "```python\n",
        "Dense(10, input_shape=[window_size], activation=\"relu\")\n",
        "```"
      ],
      "metadata": {
        "id": "NoO_DyquAgz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuy nhi√™n, l√†m sao t·ª•i m√¨nh c√≥ th·ªÉ ch·∫Øc ch·∫Øn ƒë∆∞·ª£c s·ªë **10** l√† l·ª±a ch·ªçn t·ªët nh·∫•t? ü§î N√≥ kh√° l√† ng·∫´u nhi√™n. N·∫øu b√¢y gi·ªù t·ª•i m√¨nh mu·ªën th·ª≠ nghi·ªám m·ªôt lo·∫°t c√°c s·ªë neuron kh√°c nhau cho l·ªõp **Dense** n√†y th√¨ sao? üõ†Ô∏è Ch·∫≥ng h·∫°n nh∆∞ c√°c gi√° tr·ªã trong kho·∫£ng t·ª´ **10 ƒë·∫øn 30**, t·ª•i m√¨nh c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh l·∫°i ph·∫ßn si√™u tham s·ªë nh∆∞ sau:\n",
        "\n",
        "```python\n",
        "Dense(units=hp.Int('units', min_value=10,\n",
        "                    max_value=30, step=2),\n",
        "                    activation='relu',\n",
        "                    input_shape=[window_size])\n",
        "```\n",
        "\n",
        "·ªû ƒë√¢y, m√¨nh ƒë·ªãnh nghƒ©a c√°c gi√° tr·ªã trong kho·∫£ng t·ª´ **10 ƒë·∫øn 30**, v·ªõi b∆∞·ªõc nh·∫£y l√† **2**. D·ªã l√†, ta s·∫Ω c√≥ **11 l·ªõp Dense** v·ªõi s·ªë neuron kh√°c nhau. C√¥ng c·ª• s·∫Ω ti·∫øn h√†nh hu·∫•n luy·ªán m√¥ h√¨nh **11 l·∫ßn** ƒë·ªÉ t√¨m ra s·ªë neuron t·ªëi ∆∞u nh·∫•t. üéØ\n",
        "\n",
        "T∆∞∆°ng t·ª±, t·ª•i m√¨nh c≈©ng c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh **momentum** c·ªßa h√†m t·ªëi ∆∞u b·∫±ng c√°ch:\n",
        "\n",
        "```python\n",
        "optimizer=SGD(hp.Choice('momentum', values=[.9, .7, .5, .3], lr=1e-5))\n",
        "```\n",
        "\n",
        "D·ªã l√†, n·∫øu k·∫øt h·ª£p vi·ªác t·ªëi ∆∞u h√≥a c·∫£ **optimizer** v√† l·ªõp **Dense**, th√¨ t·ª•i m√¨nh s·∫Ω c√≥ t·ªïng c·ªông **44 t·ªï h·ª£p**, t∆∞∆°ng ·ª©ng v·ªõi **44 l·∫ßn hu·∫•n luy·ªán m√¥ h√¨nh**. üìä‚ú®"
      ],
      "metadata": {
        "id": "57FYaIJZCNzf"
      }
    },
    {
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=hp.Int('units', min_value=10, max_value=30, step=2),\n",
        "                    activation='relu', input_shape=[window_size]))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Pass learning rate as 'learning_rate' in compile\n",
        "    model.compile(loss='mse',\n",
        "                  optimizer=SGD(learning_rate=1e-5,\n",
        "                                momentum=hp.Choice('momentum', values=[.9, .7, .5, .3])))\n",
        "\n",
        "    return model"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QvzNgwclXOMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh t·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng RandomSearch ƒë·ªÉ qu·∫£n l√Ω c√°c l·∫ßn l·∫∑p hu·∫•n luy·ªán m√¥ h√¨nh nha."
      ],
      "metadata": {
        "id": "jCS1-dfdSZD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner.tuners import RandomSearch\n",
        "tuner = RandomSearch(build_model,\n",
        "                     objective='loss', max_trials=150,\n",
        "                     executions_per_trial=3, directory='models',\n",
        "                     project_name='optimize_model')"
      ],
      "metadata": {
        "id": "Fm9LtKQP_rpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "M√¨nh s·∫Ω gi·∫£i th√≠ch m·ªôt s·ªë tham s·ªë c·ªßa h√†m ƒë·ªÉ m·ªçi ng∆∞·ªùi d·ªÖ hi·ªÉu h∆°n nha:  \n",
        "\n",
        "- **objective**: Ch·ªâ ƒë·ªãnh m·ª•c ti√™u c·∫ßn t·ªëi ∆∞u h√≥a. ·ªû ƒë√¢y, m·ª•c ti√™u l√† **loss**, v·ªõi mong mu·ªën gi·∫£m n√≥ xu·ªëng m·ª©c th·∫•p nh·∫•t c√≥ th·ªÉ. üéØ  \n",
        "- **max_trials**: Gi·ªõi h·∫°n t·ªïng s·ªë l·∫ßn th·ª≠ nghi·ªám t·ªëi ƒëa. ƒêi·ªÅu n√†y r·∫•t h·ªØu √≠ch trong tr∆∞·ªùng h·ª£p s·ªë l∆∞·ª£ng t·ªï h·ª£p qu√° l·ªõn, v√¨ n·∫øu hu·∫•n luy·ªán h·∫øt s·∫Ω t·ªën r·∫•t nhi·ªÅu th·ªùi gian. V√≠ d·ª•, v·ªõi 44 t·ªï h·ª£p, ta c√≥ th·ªÉ gi·ªõi h·∫°n l·∫°i b·∫±ng **20**, nghƒ©a l√† ch·ªâ hu·∫•n luy·ªán **20 l·∫ßn** thay v√¨ to√†n b·ªô. ‚è≥  \n",
        "- **execution_per_trial**: S·ªë l·∫ßn hu·∫•n luy·ªán cho m·ªói t·ªï h·ª£p. Thay v√¨ hu·∫•n luy·ªán m·ªói t·ªï h·ª£p ch·ªâ **1 l·∫ßn**, b·∫°n c√≥ th·ªÉ tƒÉng s·ªë l·∫ßn hu·∫•n luy·ªán ƒë·ªÉ gi·∫£m thi·ªÉu sai l·ªách do ng·∫´u nhi√™n trong qu√° tr√¨nh hu·∫•n luy·ªán. K·∫øt qu·∫£ b√°o c√°o s·∫Ω l√† trung b√¨nh c·ªßa c√°c l·∫ßn hu·∫•n luy·ªán ƒë√≥. üìä  \n",
        "- **directory**: Ch·ªâ ƒë·ªãnh th∆∞ m·ª•c l∆∞u l·∫°i l·ªãch s·ª≠ t√¨m ki·∫øm. Th∆∞ m·ª•c n√†y s·∫Ω ch·ª©a t·∫•t c·∫£ d·ªØ li·ªáu li√™n quan ƒë·∫øn c√°c l·∫ßn hu·∫•n luy·ªán v√† t·ªëi ∆∞u h√≥a. üóÇÔ∏è  \n",
        "- **project_name**: Ch·ªâ ƒë·ªãnh t√™n d·ª± √°n l∆∞u trong th∆∞ m·ª•c **directory**. D·ªØ li·ªáu c·ªßa d·ª± √°n s·∫Ω ƒë∆∞·ª£c l∆∞u trong m·ªôt th∆∞ m·ª•c con c√≥ t√™n t∆∞∆°ng ·ª©ng, gi√∫p t·ªï ch·ª©c th√¥ng tin m·ªôt c√°ch g·ªçn g√†ng. üõ†Ô∏è  \n",
        "\n",
        "Gi·ªù th√¨ t·ª•i m√¨nh ti·∫øn h√†nh ch·∫°y hu·∫•n luy·ªán ƒë·ªÉ t√¨m ki·∫øm ki·∫øn tr√∫c m√¥ h√¨nh t·ªët nh·∫•t ha. üöÄ‚ú®"
      ],
      "metadata": {
        "id": "-8QBQoyLTUXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timer.time()\n",
        "tuner.search(train_dataset, epochs=100, verbose=0, validation_data=val_dataset)\n",
        "end_time = timer.time()"
      ],
      "metadata": {
        "id": "nb5oQYHHYmEp"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {str(timedelta(seconds=end_time - start_time))}\")"
      ],
      "metadata": {
        "id": "yWwGlJruY6ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B√¢y gi·ªù t·ª•i m√¨nh s·∫Ω ti·∫øn h√†nh xem k·∫øt qu·∫£ ƒë√°nh gi√° nha, m·∫∑c ƒë·ªãnh th√¨ ch√∫ng s·∫Ω hi·ªÉn th·ªã 10 t·ªï h·ª£p hay ki·∫øn tr√∫c m√¥ h√¨nh t·ªët nh·∫•t ra."
      ],
      "metadata": {
        "id": "qah6NIGYa9jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "id": "Czan1Zo8aqVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê√¢y l√† k·∫øt qu·∫£ ·ªü l·∫ßn ch·∫°y c·ªßa m√¨nh nha."
      ],
      "metadata": {
        "id": "deT6uG_27bOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![tuner_list](https://github.com/Tkag0001/AI_and_Machine_Learning_for_Coders/blob/main/images/Chapter_10/tuner_list.png?raw=true)"
      ],
      "metadata": {
        "id": "-0HkTEK7LaQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "·ªû ƒë√¢y m√¨nh th·∫•y t·ªï h·ª£p hi·ªáu qu·∫£ nh·∫•t l√†  \n",
        "> units: 20  \n",
        "momentum: 0.9  \n",
        "\n",
        "M·ªçi ng∆∞·ªùi c√≥ th·ªÉ hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh v·ªõi t·ªï h·ª£p tr√™n ho·∫∑c ch·ªçn l·∫•y h·∫≥n m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán trong tuner ra lu√¥n nha. Nh∆∞ ƒëo·∫°n code d∆∞·ªõi ƒë√¢y l√† m√¨nh l·∫•y ra 4 m√¥ h√¨nh hi·ªáu qu·∫£ nh·∫•t v√† l·∫•y m√¥ h√¨nh ƒë·∫ßu ti√™n t∆∞∆°ng ·ª©ng v·ªõi m√¥ h√¨nh t·ªët nh·∫•t ƒë·ªÉ d·ª± ƒëo√°n. üåü"
      ],
      "metadata": {
        "id": "4gq7kv7KbNOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = tuner.get_best_models(num_models=4)"
      ],
      "metadata": {
        "id": "CIFc02TmbVAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = models[0]\n",
        "best_model.summary()"
      ],
      "metadata": {
        "id": "7ne6SzA17ols"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast = []\n",
        "for t in range(len(series) - window_size): # Tr·ª´ window_size v√¨ ch√∫ng ta c·∫ßn d√πng m·ªôt s·ªë l∆∞·ª£ng d·ªØ li·ªáu ban ƒë·∫ßu ƒë·ªÉ d·ª± ƒëo√°n\n",
        "  forecast.append(\n",
        "      best_model.predict(series[t:t + window_size][np.newaxis], verbose = 0)\n",
        "  )"
      ],
      "metadata": {
        "id": "8GLGVc60ymaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì d·ª± ƒëo√°n ·ªü t·∫≠p val t√≠nh t·ª´ th·ªùi ƒëi·ªÉm t = 1000\n",
        "forecast_val = forecast[start_point - window_size:] # Ch√∫ng ta c·∫ßn tr·ª´ ƒëi windown_size do index b·ªã l·ªách ƒëi b·ªüi kh√¥ng th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c n gi√° t·ªã kh·ªüi ƒë·∫ßu.\n",
        "results = np.array(forecast_val)[:, 0, 0]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, results)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "yh8xf3GMymaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ti·∫øn h√†nh ƒë√°nh gi√° MAE\n",
        "print(f\"MAE c·ªßa m√¥ h√¨nh: {keras.metrics.mean_absolute_error(x_valid, results).numpy()}\")"
      ],
      "metadata": {
        "id": "Uvijte4GhDAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nh∆∞ v·∫≠y l√† m·ªçi ng∆∞·ªùi ƒë√£ bi·∫øt ƒë∆∞·ª£c c√°ch ƒë·ªÉ c√≥ th·ªÉ ti·∫øt ki·ªám th·ªùi gian trong vi·ªác t·ªëi ∆∞u h√≥a, ch·ªçn ra c√°c b·ªô tham s·ªë t·ªët nh·∫•t cho m√¥ h√¨nh r·ªìi. M·ªçi ng∆∞·ªùi c√≥ th·ªÉ th·ª≠ th√™m nhi·ªÅu l·ª±a ch·ªçn kh√°c n·ªØa v√† quan s√°t ƒë·ªÉ c·∫£i thi·ªán m√¥ h√¨nh th√™m nha. üòä  \n",
        "\n",
        "**L∆∞u √Ω**: ·ªü ƒë√¢y t·ª•i m√¨nh ch·ªçn th∆∞·ªõc ƒëo cho tuner l√† loss m√† loss th√¨ ƒë∆∞·ª£c t√≠nh d·ª±a tr√™n t·∫≠p train n√™n c√≥ th·ªÉ khi ki·ªÉm tra tr√™n MAE c·ªßa t·∫≠p val th√¨ c√≥ th·ªÉ s·∫Ω kh√°c v√† th·∫≠m ch√≠ c√≥ tƒÉng l√™n h∆°n t√≠. M·ªçi ng∆∞·ªùi c≈©ng c√≥ th·ªÉ c√†i ƒë·∫∑t th∆∞·ªõc ƒëo t·ªëi ∆∞u h√≥a c·ªßa tuner l√† val_loss ƒë·ªÉ ch·ªçn m√¥ h√¨nh t·ªët nh·∫•t d·ª±a tr√™n val_loss nha. üìä"
      ],
      "metadata": {
        "id": "aUEzSdZdaobT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary  \n",
        "T·ªïng k·∫øt ch∆∞∆°ng 10 n√†y, t·ª•i m√¨nh ƒë√£ h·ªçc ƒë∆∞·ª£c:  \n",
        "- C√°ch x·ª≠ l√Ω d·ªØ li·ªáu th·ªùi gian ƒë·ªÉ ƒë∆∞a v√†o m√¥ h√¨nh v·ªõi c·ª≠a s·ªï tr∆∞·ª£t hay c·ª≠a s·ªï d·ªØ li·ªáu.  \n",
        "- C√°ch d·ª± ƒëo√°n v√† ƒë√°nh gi√° m√¥ h√¨nh.  \n",
        "- C√°ch s·ª≠ d·ª•ng c√¥ng c·ª• **Keras Tuner** ƒë·ªÉ c·∫£i thi·ªán qu√° tr√¨nh t·ªëi ∆∞u h√≥a m√¥ h√¨nh. ‚úÖüìò"
      ],
      "metadata": {
        "id": "ZS319bl8zbxx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOAxhbGqSkoJBUrQ0aIRd8X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}